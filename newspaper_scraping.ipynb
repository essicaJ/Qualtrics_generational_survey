{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import re\n",
    "import numpy as np\n",
    "import datetime\n",
    "from datetime import datetime, timedelta\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from newspaper import Article\n",
    "import csv\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Event</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tornadoes strike Oklahoma, Texas, Arkansas, an...</td>\n",
       "      <td>2024-05-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Boeing's Starliner capsule launches its first ...</td>\n",
       "      <td>2024-06-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Biden administration released revisions to...</td>\n",
       "      <td>2024-04-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In Planned Parenthood Arizona v. Mayes, the Ar...</td>\n",
       "      <td>2024-04-09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Event       Time\n",
       "0  Tornadoes strike Oklahoma, Texas, Arkansas, an... 2024-05-19\n",
       "1  Boeing's Starliner capsule launches its first ... 2024-06-05\n",
       "2  The Biden administration released revisions to... 2024-04-19\n",
       "3  In Planned Parenthood Arizona v. Mayes, the Ar... 2024-04-09"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load events from excel\n",
    "news_events = pd.read_excel('newsevents.xlsx', sheet_name='Sheet1')\n",
    "news_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do POS tagging and dependency parsing for every sentence to get subjec, object and predicate with spaCy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_work_token(s):\n",
    "    return bool(re.fullmatch(\"[a-zA-Z0-9-]+\", s) and s != \"-\" and not s.isnumeric())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the subject, object and predicate for every sentence\n",
    "def get_subj_obj_predicate(sentence):\n",
    "    doc = nlp(sentence)\n",
    "    keywords = {'subject': set(), 'object': set(), 'predicate': set(), 'ner': set()}\n",
    "    keywords_lemma = {'subject': set(), 'object': set(), 'predicate': set(), 'ner': set()}\n",
    "    for idx, token in enumerate(doc):\n",
    "        entry = ''\n",
    "        if token.is_stop or (token.is_punct and token.text != '-'):\n",
    "            continue\n",
    "\n",
    "        if 'subj' in token.dep_ and is_work_token(token.text):\n",
    "            entry = 'subject'\n",
    "        elif 'obj' in token.dep_ and is_work_token(token.text):\n",
    "            entry = 'object'\n",
    "        elif ('ROOT' in token.dep_ or 'prd' in token.dep_) and is_work_token(token.text):\n",
    "            entry = 'predicate'\n",
    "        elif token.ent_type_ and is_work_token(token.text):\n",
    "            entry = 'ner'\n",
    "\n",
    "        if entry in keywords:\n",
    "            keywords[entry].add(token.text)\n",
    "            keywords_lemma[entry].add(token.lemma_)\n",
    "\n",
    "        # if the work prev to the current one is compound, and the current one is a subject or object. Example: \"Donald Trump\"\n",
    "        if idx != 0 and doc[idx-1].dep_ == 'compound' and ('subj' in token.dep_ or 'obj' in token.dep_):\n",
    "            entry = 'subject' if 'subj' in token.dep_ else 'object'\n",
    "            keywords[entry].add(doc[idx-1].text)\n",
    "            keywords_lemma[entry].add(doc[idx-1].lemma_)\n",
    "\n",
    "            if '-' in doc[idx-1].text:\n",
    "                for word in doc[idx-1].text.split('-'):\n",
    "                    if word.isalpha():\n",
    "                        keywords[entry].add(word)\n",
    "                        keywords_lemma[entry].add(word)\n",
    "\n",
    "        # if the word has a hyphen, split it and add the words to the keywords. Example: COVID-19 (people may only use COVID)\n",
    "        if '-' in token.text and entry:\n",
    "            for word in token.text.split('-'):\n",
    "                if word.isalpha():\n",
    "                    keywords[entry].add(word)\n",
    "                    keywords_lemma[entry].add(word)\n",
    "\n",
    "        # if the compound word is mistakenly tagged, make it a ner entity. Example: alt-right could be mistakenly split into alt and right\n",
    "        if token.text == '-':\n",
    "            if idx != 0 and idx != len(doc)-1:\n",
    "                tok = doc[idx-1].text + '-' + doc[idx+1].text\n",
    "                keywords['ner'].add(tok)\n",
    "                keywords_lemma['ner'].add(tok)\n",
    "            \n",
    "    return keywords, keywords_lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in news_events.iterrows():\n",
    "    try_time = 0\n",
    "    keywords, keywords_lemma = get_subj_obj_predicate(row['Event'])\n",
    "    news_events.at[idx, 'Subject'] = ', '.join(keywords['subject'])\n",
    "    news_events.at[idx, 'Object'] = ', '.join(keywords['object'])\n",
    "    news_events.at[idx, 'Predicate'] = ', '.join(keywords['predicate'])\n",
    "    news_events.at[idx, 'NER'] = ', '.join(keywords['ner'])\n",
    "    news_events.at[idx, 'Subject_lemma'] = ', '.join(keywords_lemma['subject'])\n",
    "    news_events.at[idx, 'Object_lemma'] = ', '.join(keywords_lemma['object'])\n",
    "    news_events.at[idx, 'Predicate_lemma'] = ', '.join(keywords_lemma['predicate'])  \n",
    "    news_events.at[idx, 'NER_lemma'] = ', '.join(keywords_lemma['ner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Event</th>\n",
       "      <th>Time</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Object</th>\n",
       "      <th>Predicate</th>\n",
       "      <th>NER</th>\n",
       "      <th>Subject_lemma</th>\n",
       "      <th>Object_lemma</th>\n",
       "      <th>Predicate_lemma</th>\n",
       "      <th>NER_lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tornadoes strike Oklahoma, Texas, Arkansas, an...</td>\n",
       "      <td>2024-05-19</td>\n",
       "      <td>Tornadoes</td>\n",
       "      <td>people, Oklahoma</td>\n",
       "      <td>strike</td>\n",
       "      <td>Arkansas, Texas, Kentucky</td>\n",
       "      <td>tornado</td>\n",
       "      <td>people, Oklahoma</td>\n",
       "      <td>strike</td>\n",
       "      <td>Arkansas, Texas, Kentucky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Boeing's Starliner capsule launches its first ...</td>\n",
       "      <td>2024-06-05</td>\n",
       "      <td>Starliner, capsule</td>\n",
       "      <td>Space, delays, Force, Florida, space, Station,...</td>\n",
       "      <td>launches</td>\n",
       "      <td>Canaveral, Space, Starliner, astronaut-crewed,...</td>\n",
       "      <td>Starliner, capsule</td>\n",
       "      <td>Space, Force, Florida, space, Station, flight,...</td>\n",
       "      <td>launch</td>\n",
       "      <td>Canaveral, Space, Starliner, astronaut-crewed,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Biden administration released revisions to...</td>\n",
       "      <td>2024-04-19</td>\n",
       "      <td>Biden, administration</td>\n",
       "      <td>revisions, protections, rules, students, IX</td>\n",
       "      <td>released</td>\n",
       "      <td>Biden, Title, IX</td>\n",
       "      <td>Biden, administration</td>\n",
       "      <td>revision, rule, IX, student, protection</td>\n",
       "      <td>release</td>\n",
       "      <td>Biden, Title, IX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In Planned Parenthood Arizona v. Mayes, the Ar...</td>\n",
       "      <td>2024-04-09</td>\n",
       "      <td>Court, Supreme</td>\n",
       "      <td>types, Parenthood, Mayes, abortions, law, Arizona</td>\n",
       "      <td>upholds</td>\n",
       "      <td>Arizona, Supreme</td>\n",
       "      <td>Court, Supreme</td>\n",
       "      <td>type, Parenthood, Mayes, abortion, law, Arizona</td>\n",
       "      <td>uphold</td>\n",
       "      <td>Arizona, Supreme</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Event       Time  \\\n",
       "0  Tornadoes strike Oklahoma, Texas, Arkansas, an... 2024-05-19   \n",
       "1  Boeing's Starliner capsule launches its first ... 2024-06-05   \n",
       "2  The Biden administration released revisions to... 2024-04-19   \n",
       "3  In Planned Parenthood Arizona v. Mayes, the Ar... 2024-04-09   \n",
       "\n",
       "                 Subject                                             Object  \\\n",
       "0              Tornadoes                                   people, Oklahoma   \n",
       "1     Starliner, capsule  Space, delays, Force, Florida, space, Station,...   \n",
       "2  Biden, administration        revisions, protections, rules, students, IX   \n",
       "3         Court, Supreme  types, Parenthood, Mayes, abortions, law, Arizona   \n",
       "\n",
       "  Predicate                                                NER  \\\n",
       "0    strike                          Arkansas, Texas, Kentucky   \n",
       "1  launches  Canaveral, Space, Starliner, astronaut-crewed,...   \n",
       "2  released                                   Biden, Title, IX   \n",
       "3   upholds                                   Arizona, Supreme   \n",
       "\n",
       "           Subject_lemma                                       Object_lemma  \\\n",
       "0                tornado                                   people, Oklahoma   \n",
       "1     Starliner, capsule  Space, Force, Florida, space, Station, flight,...   \n",
       "2  Biden, administration            revision, rule, IX, student, protection   \n",
       "3         Court, Supreme    type, Parenthood, Mayes, abortion, law, Arizona   \n",
       "\n",
       "  Predicate_lemma                                          NER_lemma  \n",
       "0          strike                          Arkansas, Texas, Kentucky  \n",
       "1          launch  Canaveral, Space, Starliner, astronaut-crewed,...  \n",
       "2         release                                   Biden, Title, IX  \n",
       "3          uphold                                   Arizona, Supreme  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## choose (obj OR ner) AND (subj OR prd) to web scraping for news\n",
    "## timeframe: 1 month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_keywords(event):\n",
    "    obj_or_ner = f\"({event['Object']} OR {event['NER']})\"\n",
    "    subj_or_prd = f\"({event['Subject']} OR {event['Predicate']})\"\n",
    "    return f\"{obj_or_ner} AND {subj_or_prd}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Keywords for event 'Tornadoes strike Oklahoma, Texas, Arkansas, and Kentucky, killing 21 people': (people, Oklahoma OR Arkansas, Texas, Kentucky) AND (Tornadoes OR strike)\n",
      "Generated Keywords for event 'Boeing's Starliner capsule launches its first astronaut-crewed flight into space to the International Space Station after several delays at the Cape Canaveral Space Force Station in Florida.': (Space, delays, Force, Florida, space, Station, flight OR Canaveral, Space, Starliner, astronaut-crewed, Force, International, Cape, Boeing) AND (Starliner, capsule OR launches)\n",
      "Generated Keywords for event 'The Biden administration released revisions to Title IX rules which give further protections for LGBTQ+ students as well as parenting and pregnant students.': (revisions, protections, rules, students, IX OR Biden, Title, IX) AND (Biden, administration OR released)\n",
      "Generated Keywords for event 'In Planned Parenthood Arizona v. Mayes, the Arizona Supreme Court upholds an 1864 law that disallows most types of abortions': (types, Parenthood, Mayes, abortions, law, Arizona OR Arizona, Supreme) AND (Court, Supreme OR upholds)\n"
     ]
    }
   ],
   "source": [
    "for event in news_events.to_dict(orient='records'):\n",
    "    keywords = generate_keywords(event)\n",
    "    print(f\"Generated Keywords for event '{event['Event']}': {keywords}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_date_range(event_date):\n",
    "    if not isinstance(event_date, str):\n",
    "        event_date = event_date.strftime('%Y-%m-%d')\n",
    "    start_date = datetime.strptime(event_date, '%Y-%m-%d')\n",
    "    end_date = start_date + timedelta(days=30)\n",
    "    return start_date.strftime('%Y-%m-%d'), end_date.strftime('%Y-%m-%d')\n",
    "\n",
    "def search_news(keywords, start_date, end_date):\n",
    "    encoded_keywords = urllib.parse.quote(keywords)\n",
    "    search_url = f\"https://news.google.com/search?q={encoded_keywords}%20after:{start_date}%20before:{end_date}\"\n",
    "    articles = []\n",
    "\n",
    "    while search_url:\n",
    "        print(f\"Searching for news with URL: {search_url}\")\n",
    "        response = requests.get(search_url)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "        for link in soup.find_all('a', class_='WwrzSb'):\n",
    "            url = link.get('href')\n",
    "            if url and url.startswith('./articles/'):\n",
    "                full_url = f\"https://news.google.com{url[1:]}\"\n",
    "                articles.append(full_url)\n",
    "\n",
    "        next_button = soup.find('a', class_='nBDE1b G5eFlf')\n",
    "        search_url = f\"https://news.google.com{next_button['href'][1:]}\" if next_button else None\n",
    "\n",
    "    return articles\n",
    "\n",
    "def collect_content(tag_list):\n",
    "    return ' '.join([tag.get_text() for tag in tag_list])\n",
    "\n",
    "def collect_content_USA(tag_list):\n",
    "    return ' '.join([tag.get_text() for tag in tag_list])\n",
    "\n",
    "def get_content(url):\n",
    "    session = requests.Session()\n",
    "    response = session.get(url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "    print('getting content from url: ', url)\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        print('Error with request')\n",
    "        html = ''\n",
    "    else:\n",
    "        html = response.content\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    div_tag = soup.findAll('div', class_='article-body')\n",
    "    div_tag2 = soup.findAll('div', class_='article-content')\n",
    "    div_tag3 = soup.findAll('p', class_='gnt_ar_b_p')  # USA Today\n",
    "    div_tag4 = soup.findAll('div', class_='article__text | body-copy | flow')  # The Hill\n",
    "    div_tag5 = soup.findAll('div', class_='primary-cli cli cli-text')\n",
    "\n",
    "    if div_tag:\n",
    "        return collect_content(div_tag)\n",
    "    elif div_tag2:\n",
    "        return collect_content(div_tag2)\n",
    "    elif div_tag3:\n",
    "        return collect_content_USA(div_tag3)\n",
    "    elif div_tag4:\n",
    "        return collect_content(div_tag4)\n",
    "    elif div_tag5:\n",
    "        return collect_content(div_tag5)\n",
    "    else:\n",
    "        c_list = [v.text for v in soup.find_all('p') if len(v.text) > 0]\n",
    "        words_to_bans = ['<', 'javascript']\n",
    "        for word_to_ban in words_to_bans:\n",
    "            c_list = list(filter(lambda x: word_to_ban not in x.lower(), c_list))\n",
    "        c_list = [t for t in c_list if len(re.findall('[a-z]', t.lower())) / (len(t) + 1) < 0.8]\n",
    "        content = ' '.join(c_list)\n",
    "        content = content.replace('\\n', ' ')\n",
    "        content = re.sub('\\s\\s+', ' ', content)  # remove multiple spaces.\n",
    "        return content\n",
    "\n",
    "def get_article_details(url):\n",
    "    try:\n",
    "        article = Article(url)\n",
    "        article.download()\n",
    "        article.parse()\n",
    "\n",
    "        # Check if the article text was parsed\n",
    "        if not article.text:\n",
    "            raise ValueError(\"No content parsed by newspaper3k\")\n",
    "\n",
    "        return article.publish_date, article.source_url, article.url, article.text\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing article with newspaper3k: {e}\")\n",
    "        print(\"Attempting to manually extract content...\")\n",
    "\n",
    "        try:\n",
    "            article_content = get_content(url)\n",
    "\n",
    "            # Attempt to manually extract publish date\n",
    "            response = requests.get(url)\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            meta_date = soup.find('meta', {'property': 'article:published_time'})\n",
    "            article_date = meta_date['content'] if meta_date else 'Unknown'\n",
    "\n",
    "            return article_date, url, url, article_content\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to manually extract content from {url}: {e}\")\n",
    "            return None, None, url, \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for news articles for event 'Tornadoes strike Oklahoma, Texas, Arkansas, and Kentucky, killing 21 people' between 2024-05-19 and 2024-06-18\n",
      "Searching for news with URL: https://news.google.com/search?q=%28people%2C%20Oklahoma%20OR%20Arkansas%2C%20Texas%2C%20Kentucky%29%20AND%20%28Tornadoes%20OR%20strike%29%20after:2024-05-19%20before:2024-06-18\n",
      "Error parsing article with newspaper3k: No content parsed by newspaper3k\n",
      "Attempting to manually extract content...\n",
      "getting content from url:  https://news.google.com/articles/CBMibmh0dHBzOi8vYXBuZXdzLmNvbS9hcnRpY2xlL3Rvcm5hZG9lcy13ZWF0aGVyLXRleGFzLW9rbGFob21hLWFya2Fuc2FzLWtlbnR1Y2t5LTkxYjBmZjVjMDZmOWJkYzhiOGNhNjhmMzZhZmJhZmEy0gEA?hl=en-US&gl=US&ceid=US%3Aen\n",
      "Error parsing article with newspaper3k: No content parsed by newspaper3k\n",
      "Attempting to manually extract content...\n",
      "getting content from url:  https://news.google.com/articles/CBMiSmh0dHBzOi8vd3d3Lm5wci5vcmcvMjAyNC8wNS8yNi9nLXMxLTEwOTIvdG9ybmFkb2VzLXRleGFzLW9rbGFob21hLWFya2Fuc2Fz0gEA?hl=en-US&gl=US&ceid=US%3Aen\n",
      "Error parsing article with newspaper3k: No content parsed by newspaper3k\n",
      "Attempting to manually extract content...\n",
      "getting content from url:  https://news.google.com/articles/CBMiaWh0dHBzOi8vd3d3LmNubi5jb20vd2VhdGhlci9saXZlLW5ld3Mvb2tsYWhvbWEtdGV4YXMtYXJrYW5zYXMtdG9ybmFkby1zdG9ybXMtMDUtMjctMjQtaW50bC1obmsvaW5kZXguaHRtbNIBAA?hl=en-US&gl=US&ceid=US%3Aen\n",
      "Error parsing article with newspaper3k: No content parsed by newspaper3k\n",
      "Attempting to manually extract content...\n",
      "getting content from url:  https://news.google.com/articles/CBMid2h0dHBzOi8vd3d3LndnYmgub3JnL25ld3MvMjAyNC0wNS0yNi9tb3JlLXRoYW4tMjAtYXJlLWRlYWQtYWZ0ZXItdG9ybmFkb2VzLXJpcC10aHJvdWdoLXBhcnRzLW9mLXRleGFzLWtlbnR1Y2t5LWFya2Fuc2Fz0gEA?hl=en-US&gl=US&ceid=US%3Aen\n",
      "Error parsing article with newspaper3k: No content parsed by newspaper3k\n",
      "Attempting to manually extract content...\n",
      "getting content from url:  https://news.google.com/articles/CBMiSmh0dHBzOi8vd3d3Lm55dGltZXMuY29tLzIwMjQvMDUvMjYvdXMvdG9ybmFkb2VzLXN0b3Jtcy10ZXhhcy1va2xhaG9tYS5odG1s0gEA?hl=en-US&gl=US&ceid=US%3Aen\n",
      "Error parsing article with newspaper3k: No content parsed by newspaper3k\n",
      "Attempting to manually extract content...\n",
      "getting content from url:  https://news.google.com/articles/CBMiXmh0dHBzOi8vd2VhdGhlci5jb20vbmV3cy93ZWF0aGVyL25ld3MvMjAyNC0wNS0yNS1kZWFkbHktdG9ybmFkby10ZXhhcy1va2xhaG9tYS1hcmthbnNhcy1zdG9ybXPSAQA?hl=en-US&gl=US&ceid=US%3Aen\n",
      "Error parsing article with newspaper3k: No content parsed by newspaper3k\n",
      "Attempting to manually extract content...\n",
      "getting content from url:  https://news.google.com/articles/CBMidGh0dHBzOi8vd3d3LnJldXRlcnMuY29tL3dvcmxkL3VzL3Rvcm5hZG9lcy1oaXQtdGV4YXMtYXJrYW5zYXMtb2tsYWhvbWEta2lsbGluZy1sZWFzdC0yLXRleGFzLW55dC1yZXBvcnRzLTIwMjQtMDUtMjYv0gEA?hl=en-US&gl=US&ceid=US%3Aen\n",
      "Error parsing article with newspaper3k: No content parsed by newspaper3k\n",
      "Attempting to manually extract content...\n",
      "getting content from url:  https://news.google.com/articles/CBMidWh0dHBzOi8vd3d3LnVzYXRvZGF5LmNvbS9zdG9yeS9uZXdzL25hdGlvbi8yMDI0LzA1LzI2L3RleGFzLW9rbGFob21hLXRvcm5hZG8tc2V2ZXJlLXdlYXRoZXItbGl2ZS11cGRhdGVzLzczODYxNzc2MDA3L9IBAA?hl=en-US&gl=US&ceid=US%3Aen\n",
      "Error parsing article with newspaper3k: No content parsed by newspaper3k\n",
      "Attempting to manually extract content...\n",
      "getting content from url:  https://news.google.com/articles/CBMiVmh0dHBzOi8vd3d3LmNic25ld3MuY29tL25ld3Mvc3Rvcm1zLWtpbGwtYXQtbGVhc3QtMTktdGV4YXMta2VudHVja3ktYXJrYW5zYXMtb2tsYWhvbWEv0gFaaHR0cHM6Ly93d3cuY2JzbmV3cy5jb20vYW1wL25ld3Mvc3Rvcm1zLWtpbGwtYXQtbGVhc3QtMTktdGV4YXMta2VudHVja3ktYXJrYW5zYXMtb2tsYWhvbWEv?hl=en-US&gl=US&ceid=US%3Aen\n",
      "Error parsing article with newspaper3k: No content parsed by newspaper3k\n",
      "Attempting to manually extract content...\n",
      "getting content from url:  https://news.google.com/articles/CBMiLmh0dHBzOi8vd3d3LmJiYy5jb20vbmV3cy9hcnRpY2xlcy9jeHh4cDF3NmUycm_SATJodHRwczovL3d3dy5iYmMuY29tL25ld3MvYXJ0aWNsZXMvY3h4eHAxdzZlMnJvLmFtcA?hl=en-US&gl=US&ceid=US%3Aen\n",
      "Error parsing article with newspaper3k: No content parsed by newspaper3k\n",
      "Attempting to manually extract content...\n",
      "getting content from url:  https://news.google.com/articles/CBMidGh0dHBzOi8vd3d3Lm5iY25ld3MuY29tL25ld3Mvd2VhdGhlci8zNTAwMDAtcG93ZXItbWlzc291cmktYXJrYW5zYXMta2VudHVja3ktc3Rvcm1zLWJhdHRlci1taWRkbGUtYW1lcmljYS1yY25hMTU0MTE10gEraHR0cHM6Ly93d3cubmJjbmV3cy5jb20vbmV3cy9hbXAvcmNuYTE1NDExNQ?hl=en-US&gl=US&ceid=US%3Aen\n",
      "Error parsing article with newspaper3k: No content parsed by newspaper3k\n",
      "Attempting to manually extract content...\n",
      "getting content from url:  https://news.google.com/articles/CBMib2h0dHBzOi8vd3d3LnBicy5vcmcvbmV3c2hvdXIvbmF0aW9uL3dlZWtlbmQtdG9ybmFkb2VzLWtpbGwtYXQtbGVhc3QtMjItYWNyb3NzLXRoZS11LXMtd2l0aC1tb3JlLXN0b3Jtcy1wb3NzaWJsZdIBc2h0dHBzOi8vd3d3LnBicy5vcmcvbmV3c2hvdXIvYW1wL25hdGlvbi93ZWVrZW5kLXRvcm5hZG9lcy1raWxsLWF0LWxlYXN0LTIyLWFjcm9zcy10aGUtdS1zLXdpdGgtbW9yZS1zdG9ybXMtcG9zc2libGU?hl=en-US&gl=US&ceid=US%3Aen\n",
      "Error parsing article with newspaper3k: No content parsed by newspaper3k\n",
      "Attempting to manually extract content...\n",
      "getting content from url:  https://news.google.com/articles/CBMiiAFodHRwczovL3d3dy50aW1lc25vd25ld3MuY29tL3dvcmxkL3VzL3VzLW5ld3MvdGV4YXMtb2tsYWhvbWEta2VudHVja3ktYXJrYW5zYXMtdG9ybmFkby1kZWF0aC10b2xsLWluanVyaWVzZGFtYWdldXBkYXRlLWFydGljbGUtMTEwNDQ0ODE50gGMAWh0dHBzOi8vd3d3LnRpbWVzbm93bmV3cy5jb20vd29ybGQvdXMvdXMtbmV3cy90ZXhhcy1va2xhaG9tYS1rZW50dWNreS1hcmthbnNhcy10b3JuYWRvLWRlYXRoLXRvbGwtaW5qdXJpZXNkYW1hZ2V1cGRhdGUtYXJ0aWNsZS0xMTA0NDQ4MTkvYW1w?hl=en-US&gl=US&ceid=US%3Aen\n",
      "Error parsing article with newspaper3k: No content parsed by newspaper3k\n",
      "Attempting to manually extract content...\n",
      "getting content from url:  https://news.google.com/articles/CBMiXmh0dHBzOi8vd3d3Lm5lY24uY29tL25ld3MvbmF0aW9uYWwtaW50ZXJuYXRpb25hbC90ZXhhcy1va2xhaG9tYS1zZXZlcmUtd2VhdGhlci1kYW1hZ2UvMzI0Mzc4Ny_SAWRodHRwczovL3d3dy5uZWNuLmNvbS9uZXdzL25hdGlvbmFsLWludGVybmF0aW9uYWwvdGV4YXMtb2tsYWhvbWEtc2V2ZXJlLXdlYXRoZXItZGFtYWdlLzMyNDM3ODcvP2FtcD0x?hl=en-US&gl=US&ceid=US%3Aen\n",
      "Error parsing article with newspaper3k: No content parsed by newspaper3k\n",
      "Attempting to manually extract content...\n",
      "getting content from url:  https://news.google.com/articles/CBMiXWh0dHBzOi8vd3d3Lndhc2hpbmd0b25wb3N0LmNvbS93ZWF0aGVyLzIwMjQvMDUvMjcvdG9ybmFkby1rZW50dWNreS10ZXhhcy1zdG9ybXMtd2VhdGhlci1uZXdzL9IBAA?hl=en-US&gl=US&ceid=US%3Aen\n",
      "Error parsing article with newspaper3k: No content parsed by newspaper3k\n",
      "Attempting to manually extract content...\n",
      "getting content from url:  https://news.google.com/articles/CBMimQFodHRwczovL3d3dy5kYWxsYXNuZXdzLmNvbS9uZXdzL3dlYXRoZXIvMjAyNC8wNS8yNy9tZW1vcmlhbC1kYXktd2Vla2VuZC1zdG9ybXMta2lsbC1hdC1sZWFzdC0yMS1kZXZhc3RhdGVzLXRvd25zLWluLXRleGFzLW9rbGFob21hLWFya2Fuc2FzLWFuZC1rZW50dWNreS_SAagBaHR0cHM6Ly93d3cuZGFsbGFzbmV3cy5jb20vbmV3cy93ZWF0aGVyLzIwMjQvMDUvMjcvbWVtb3JpYWwtZGF5LXdlZWtlbmQtc3Rvcm1zLWtpbGwtYXQtbGVhc3QtMjEtZGV2YXN0YXRlcy10b3ducy1pbi10ZXhhcy1va2xhaG9tYS1hcmthbnNhcy1hbmQta2VudHVja3kvP291dHB1dFR5cGU9YW1w?hl=en-US&gl=US&ceid=US%3Aen\n",
      "Error parsing article with newspaper3k: No content parsed by newspaper3k\n",
      "Attempting to manually extract content...\n",
      "getting content from url:  https://news.google.com/articles/CBMiogFodHRwczovL3d3dy5zY21wLmNvbS9uZXdzL3dvcmxkL3VuaXRlZC1zdGF0ZXMtY2FuYWRhL2FydGljbGUvMzI2NDE4NS9tdWx0aXBsZS1kZWF0aHMtcmVwb3J0ZWQtdGV4YXMtb2tsYWhvbWEtYW5kLWFya2Fuc2FzLWFmdGVyLXBvd2VyZnVsLXN0b3Jtcy1yb2FyLWFjcm9zcy1yZWdpb27SAaIBaHR0cHM6Ly9hbXAuc2NtcC5jb20vbmV3cy93b3JsZC91bml0ZWQtc3RhdGVzLWNhbmFkYS9hcnRpY2xlLzMyNjQxODUvbXVsdGlwbGUtZGVhdGhzLXJlcG9ydGVkLXRleGFzLW9rbGFob21hLWFuZC1hcmthbnNhcy1hZnRlci1wb3dlcmZ1bC1zdG9ybXMtcm9hci1hY3Jvc3MtcmVnaW9u?hl=en-US&gl=US&ceid=US%3Aen\n",
      "Error parsing article with newspaper3k: No content parsed by newspaper3k\n",
      "Attempting to manually extract content...\n",
      "getting content from url:  https://news.google.com/articles/CBMiaGh0dHBzOi8vd3d3LmNubi5jb20vdmlkZW9zL3dlYXRoZXIvMjAyNC8wNS8yNy9rZW50dWNreS10b3JuYWRvLXRleGFzLWFya2Fuc2FzLW9rbGFob21hLWRhbWFnZS1kaWd2aWQuY25u0gEA?hl=en-US&gl=US&ceid=US%3Aen\n",
      "Error parsing article with newspaper3k: No content parsed by newspaper3k\n",
      "Attempting to manually extract content...\n",
      "getting content from url:  https://news.google.com/articles/CBMigAFodHRwczovL3d3dy51c2F0b2RheS5jb20vc3RvcnkvbmV3cy9uYXRpb24vMjAyNC8wNS8yNy8xOS1kZWFkLXRvcm5hZG9lcy1tZW1vcmlhbC1kYXktc3Rvcm1zLXRleGFzLWFya2Fuc2FzLW9rbGFob21hLzczODY4MDc5MDA3L9IBAA?hl=en-US&gl=US&ceid=US%3Aen\n",
      "Error parsing article with newspaper3k: No content parsed by newspaper3k\n",
      "Attempting to manually extract content...\n",
      "getting content from url:  https://news.google.com/articles/CBMihgFodHRwczovL3d3dy5idXNpbmVzcy1zdGFuZGFyZC5jb20vd29ybGQtbmV3cy90b3JuYWRvZXMtcmlwLXRocm91Z2gtdGV4YXMtb2tsYWhvbWEtYXJrYW5zYXMtYXQtbGVhc3QtMTktcGVvcGxlLWRlYWQtMTI0MDUyNzAxMjUxXzEuaHRtbNIBigFodHRwczovL3d3dy5idXNpbmVzcy1zdGFuZGFyZC5jb20vYW1wL3dvcmxkLW5ld3MvdG9ybmFkb2VzLXJpcC10aHJvdWdoLXRleGFzLW9rbGFob21hLWFya2Fuc2FzLWF0LWxlYXN0LTE5LXBlb3BsZS1kZWFkLTEyNDA1MjcwMTI1MV8xLmh0bWw?hl=en-US&gl=US&ceid=US%3Aen\n",
      "Error parsing article with newspaper3k: No content parsed by newspaper3k\n",
      "Attempting to manually extract content...\n",
      "getting content from url:  https://news.google.com/articles/CBMiUWh0dHBzOi8vd3d3LmNic25ld3MuY29tL25ld3Mvd2VhdGhlci1zdG9ybS1kYW5nZXJvdXMtaGVhdC10b3JuYWRvZXMtbWVtb3JpYWwtZGF5L9IBVWh0dHBzOi8vd3d3LmNic25ld3MuY29tL2FtcC9uZXdzL3dlYXRoZXItc3Rvcm0tZGFuZ2Vyb3VzLWhlYXQtdG9ybmFkb2VzLW1lbW9yaWFsLWRheS8?hl=en-US&gl=US&ceid=US%3Aen\n",
      "Error parsing article with newspaper3k: No content parsed by newspaper3k\n",
      "Attempting to manually extract content...\n",
      "getting content from url:  https://news.google.com/articles/CBMieGh0dHBzOi8vd3d3LnZvYW5ld3MuY29tL2EvYXQtbGVhc3QtMjAtZGVhZC1pbi1tZW1vcmlhbC1kYXktd2Vla2VuZC1zdG9ybXMtdGhhdC1kZXZhc3RhdGVkLXNldmVyYWwtdXMtc3RhdGVzLzc2Mjg2MDQuaHRtbNIBemh0dHBzOi8vd3d3LnZvYW5ld3MuY29tL2FtcC9hdC1sZWFzdC0yMC1kZWFkLWluLW1lbW9yaWFsLWRheS13ZWVrZW5kLXN0b3Jtcy10aGF0LWRldmFzdGF0ZWQtc2V2ZXJhbC11cy1zdGF0ZXMvNzYyODYwNC5odG1s?hl=en-US&gl=US&ceid=US%3Aen\n",
      "Error parsing article with newspaper3k: No content parsed by newspaper3k\n",
      "Attempting to manually extract content...\n",
      "getting content from url:  https://news.google.com/articles/CBMiXmh0dHBzOi8vd3d3LmNubi5jb20vd2VhdGhlci9saXZlLW5ld3Mvb2tsYWhvbWEtdGV4YXMta2Fuc2FzLXRvcm5hZG8tc3Rvcm1zLTA1LTI2LTI0L2luZGV4Lmh0bWzSAQA?hl=en-US&gl=US&ceid=US%3Aen\n",
      "Error parsing article with newspaper3k: No content parsed by newspaper3k\n",
      "Attempting to manually extract content...\n",
      "getting content from url:  https://news.google.com/articles/CBMihwFodHRwczovL3d3dy5mb3JiZXMuY29tL3NpdGVzL21hcnlyb2Vsb2Zmcy8yMDI0LzA1LzI3L2RlYXRoLXRvbGwtZnJvbS1zZXZlcmUtc3Rvcm1zLWluLXRleGFzLWFuZC1uZWFyYnktc3RhdGVzLXJpc2VzLXRvLTIxLXdoYXQtd2Uta25vdy_SAQA?hl=en-US&gl=US&ceid=US%3Aen\n",
      "Error parsing article with newspaper3k: No content parsed by newspaper3k\n",
      "Attempting to manually extract content...\n",
      "getting content from url:  https://news.google.com/articles/CBMiWGh0dHBzOi8vYWJjN255LmNvbS9wb3N0LzE4LWRlYWQtdGV4YXMtb2tsYWhvbWEtYXJrYW5zYXMtbWlzc291cmkta2Fuc2FzLXNldmVyZS8xNDg3Njg2NS_SAQA?hl=en-US&gl=US&ceid=US%3Aen\n",
      "Error parsing article with newspaper3k: No content parsed by newspaper3k\n",
      "Attempting to manually extract content...\n",
      "getting content from url:  https://news.google.com/articles/CBMiVmh0dHBzOi8vd3d3LmNubi5jb20vMjAyNC8wNS8yNi93ZWF0aGVyL21lbW9yaWFsLWRheS13ZWVrZW5kLWZvcmVjYXN0LXN1bmRheS9pbmRleC5odG1s0gFPaHR0cHM6Ly9hbXAuY25uLmNvbS9jbm4vMjAyNC8wNS8yNi93ZWF0aGVyL21lbW9yaWFsLWRheS13ZWVrZW5kLWZvcmVjYXN0LXN1bmRheQ?hl=en-US&gl=US&ceid=US%3Aen\n",
      "Error parsing article with newspaper3k: No content parsed by newspaper3k\n",
      "Attempting to manually extract content...\n",
      "getting content from url:  https://news.google.com/articles/CBMidmh0dHBzOi8vd3d3LnVzYXRvZGF5LmNvbS9zdG9yeS9uZXdzL25hdGlvbi8yMDI0LzA1LzI4L3NldmVyZS1zdG9ybXMtdG9ybmFkb2VzLW1lbW9yaWFsLWRheS13ZWVrZW5kLXBob3Rvcy83Mzg3NDc1MTAwNy_SAQA?hl=en-US&gl=US&ceid=US%3Aen\n",
      "Error parsing article with newspaper3k: No content parsed by newspaper3k\n",
      "Attempting to manually extract content...\n",
      "getting content from url:  https://news.google.com/articles/CBMiamh0dHBzOi8vd3d3LnRoZWd1YXJkaWFuLmNvbS91cy1uZXdzL2FydGljbGUvMjAyNC9tYXkvMjYvcG93ZXJmdWwtc3Rvcm1zLXRlYXItdGhyb3VnaC1ydXJhbC10ZXhhbi1jb21tdW5pdHnSAWpodHRwczovL2FtcC50aGVndWFyZGlhbi5jb20vdXMtbmV3cy9hcnRpY2xlLzIwMjQvbWF5LzI2L3Bvd2VyZnVsLXN0b3Jtcy10ZWFyLXRocm91Z2gtcnVyYWwtdGV4YW4tY29tbXVuaXR5?hl=en-US&gl=US&ceid=US%3Aen\n",
      "Error parsing article with newspaper3k: No content parsed by newspaper3k\n",
      "Attempting to manually extract content...\n",
      "getting content from url:  https://news.google.com/articles/CBMiVGh0dHBzOi8vd3d3LmZveHdlYXRoZXIuY29tL3dlYXRoZXItbmV3cy9tZW1vcmlhbC1kYXktd2Vla2VuZC1zZXZlcmUtd2VhdGhlci1mb3JlY2FzdNIBWGh0dHBzOi8vd3d3LmZveHdlYXRoZXIuY29tL3dlYXRoZXItbmV3cy9tZW1vcmlhbC1kYXktd2Vla2VuZC1zZXZlcmUtd2VhdGhlci1mb3JlY2FzdC5hbXA?hl=en-US&gl=US&ceid=US%3Aen\n",
      "Error parsing article with newspaper3k: No content parsed by newspaper3k\n",
      "Attempting to manually extract content...\n",
      "getting content from url:  https://news.google.com/articles/CBMifGh0dHBzOi8vd3d3LnRwci5vcmcvZW52aXJvbm1lbnQvMjAyNC0wNS0yNi9hdC1sZWFzdC0xOC1hcmUtZGVhZC1hZnRlci10b3JuYWRvZXMtcmlwLXRocm91Z2gtcGFydHMtb2YtdGV4YXMtb2tsYWhvbWEtYXJrYW5zYXPSAQA?hl=en-US&gl=US&ceid=US%3Aen\n",
      "Error parsing article with newspaper3k: No content parsed by newspaper3k\n",
      "Attempting to manually extract content...\n",
      "getting content from url:  https://news.google.com/articles/CBMiemh0dHBzOi8vd3d3Lndzai5jb20vdXMtbmV3cy9jbGltYXRlLWVudmlyb25tZW50L2F0LWxlYXN0LWZpdmUta2lsbGVkLWluLXRleGFzLXN0b3Jtcy1hcy1zZXZlcmUtd2VhdGhlci1oZWFkcy1lYXN0LTE4Mjk1MmNl0gEA?hl=en-US&gl=US&ceid=US%3Aen\n",
      "Error parsing article with newspaper3k: No content parsed by newspaper3k\n",
      "Attempting to manually extract content...\n",
      "getting content from url:  https://news.google.com/articles/CBMiQmh0dHBzOi8vd3d3LmF4aW9zLmNvbS8yMDI0LzA1LzI1L3NldmVyZS13ZWF0aGVyLXRvcm5hZG9lcy1va2xhaG9tYdIBAA?hl=en-US&gl=US&ceid=US%3Aen\n",
      "Error parsing article with newspaper3k: No content parsed by newspaper3k\n",
      "Attempting to manually extract content...\n",
      "getting content from url:  https://news.google.com/articles/CBMimAFodHRwczovL20uZWNvbm9taWN0aW1lcy5jb20vbmV3cy9pbnRlcm5hdGlvbmFsL3dvcmxkLW5ld3MvYXQtbGVhc3QtMTQtZGVhZC1mcm9tLXN0b3Jtcy1pbi10ZXhhcy1hcmthbnNhcy1va2xhaG9tYS1hbmQta2VudHVja3kvYXJ0aWNsZXNob3cvMTEwNDQ4OTIxLmNtc9IBnAFodHRwczovL20uZWNvbm9taWN0aW1lcy5jb20vbmV3cy9pbnRlcm5hdGlvbmFsL3dvcmxkLW5ld3MvYXQtbGVhc3QtMTQtZGVhZC1mcm9tLXN0b3Jtcy1pbi10ZXhhcy1hcmthbnNhcy1va2xhaG9tYS1hbmQta2VudHVja3kvYW1wX2FydGljbGVzaG93LzExMDQ0ODkyMS5jbXM?hl=en-US&gl=US&ceid=US%3Aen\n",
      "Error parsing article with newspaper3k: No content parsed by newspaper3k\n",
      "Attempting to manually extract content...\n",
      "getting content from url:  https://news.google.com/articles/CBMia2h0dHBzOi8vd3d3LmFsamF6ZWVyYS5jb20vbmV3cy8yMDI0LzUvMjcvZGVhdGgtdG9sbC1yaXNlcy10by0yMS1hZnRlci1zdG9ybXMtc3dlZXAtYWNyb3NzLXNldmVyYWwtdXMtc3RhdGVz0gFvaHR0cHM6Ly93d3cuYWxqYXplZXJhLmNvbS9hbXAvbmV3cy8yMDI0LzUvMjcvZGVhdGgtdG9sbC1yaXNlcy10by0yMS1hZnRlci1zdG9ybXMtc3dlZXAtYWNyb3NzLXNldmVyYWwtdXMtc3RhdGVz?hl=en-US&gl=US&ceid=US%3Aen\n",
      "Error parsing article with newspaper3k: No content parsed by newspaper3k\n",
      "Attempting to manually extract content...\n",
      "getting content from url:  https://news.google.com/articles/CBMigAFodHRwczovL3d3dy5kYWxsYXNuZXdzLmNvbS9uZXdzL3dlYXRoZXIvMjAyNC8wNS8yNi9hdC1sZWFzdC0xMS1kZWFkLWluLXRleGFzLW9rbGFob21hLWFuZC1hcmthbnNhcy1hZnRlci1uaWdodC1vZi1zZXZlcmUtc3Rvcm1zL9IBjwFodHRwczovL3d3dy5kYWxsYXNuZXdzLmNvbS9uZXdzL3dlYXRoZXIvMjAyNC8wNS8yNi9hdC1sZWFzdC0xMS1kZWFkLWluLXRleGFzLW9rbGFob21hLWFuZC1hcmthbnNhcy1hZnRlci1uaWdodC1vZi1zZXZlcmUtc3Rvcm1zLz9vdXRwdXRUeXBlPWFtcA?hl=en-US&gl=US&ceid=US%3Aen\n",
      "Error parsing article with newspaper3k: No content parsed by newspaper3k\n",
      "Attempting to manually extract content...\n",
      "getting content from url:  https://news.google.com/articles/CBMiYmh0dHBzOi8vdGhlaGlsbC5jb20vcG9saWN5L2VuZXJneS1lbnZpcm9ubWVudC80Njg3Njg2LXNldmVyZS1zdG9ybXMtdXBlbmRpbmctbWVtb3JpYWwtZGF5LXdlZWtlbmQv0gFmaHR0cHM6Ly90aGVoaWxsLmNvbS9wb2xpY3kvZW5lcmd5LWVudmlyb25tZW50LzQ2ODc2ODYtc2V2ZXJlLXN0b3Jtcy11cGVuZGluZy1tZW1vcmlhbC1kYXktd2Vla2VuZC9hbXAv?hl=en-US&gl=US&ceid=US%3Aen\n",
      "Error parsing article with newspaper3k: No content parsed by newspaper3k\n",
      "Attempting to manually extract content...\n",
      "getting content from url:  https://news.google.com/articles/CBMiVGh0dHBzOi8vd3d3LmZveHdlYXRoZXIuY29tL3dlYXRoZXItbmV3cy9zZXZlcmUtd2VhdGhlci10b3JuYWRvZXMtbWVtb3JpYWwtZGF5LXN1bmRhedIBWGh0dHBzOi8vd3d3LmZveHdlYXRoZXIuY29tL3dlYXRoZXItbmV3cy9zZXZlcmUtd2VhdGhlci10b3JuYWRvZXMtbWVtb3JpYWwtZGF5LXN1bmRheS5hbXA?hl=en-US&gl=US&ceid=US%3Aen\n",
      "Error parsing article with newspaper3k: No content parsed by newspaper3k\n",
      "Attempting to manually extract content...\n",
      "getting content from url:  https://news.google.com/articles/CBMifGh0dHBzOi8vd3d3LnRoZXdlZWsuaW4vbmV3cy93b3JsZC8yMDI0LzA1LzI3L3VzLXRvcm5hZG9lcy0xOS1kZWFkLWFzLXBvd2VyZnVsLXN0b3Jtcy1yYXZhZ2UtdGV4YXMtb2tsYWhvbWEtYW5kLWFya2Fuc2FzLmh0bWzSAYABaHR0cHM6Ly93d3cudGhld2Vlay5pbi9uZXdzL3dvcmxkLzIwMjQvMDUvMjcvdXMtdG9ybmFkb2VzLTE5LWRlYWQtYXMtcG93ZXJmdWwtc3Rvcm1zLXJhdmFnZS10ZXhhcy1va2xhaG9tYS1hbmQtYXJrYW5zYXMuYW1wLmh0bWw?hl=en-US&gl=US&ceid=US%3Aen\n",
      "Error parsing article with newspaper3k: No content parsed by newspaper3k\n",
      "Attempting to manually extract content...\n",
      "getting content from url:  https://news.google.com/articles/CBMiXGh0dHBzOi8vd3d3LnRoZWd1YXJkaWFuLmNvbS91cy1uZXdzL2FydGljbGUvMjAyNC9tYXkvMjcvc3Rvcm1zLWRlc3RydWN0aW9uLWFjcm9zcy1jZW50cmFsLXVz0gFcaHR0cHM6Ly9hbXAudGhlZ3VhcmRpYW4uY29tL3VzLW5ld3MvYXJ0aWNsZS8yMDI0L21heS8yNy9zdG9ybXMtZGVzdHJ1Y3Rpb24tYWNyb3NzLWNlbnRyYWwtdXM?hl=en-US&gl=US&ceid=US%3Aen\n",
      "Error parsing article with newspaper3k: No content parsed by newspaper3k\n",
      "Attempting to manually extract content...\n",
      "getting content from url:  https://news.google.com/articles/CBMiLGh0dHBzOi8vd3d3LmJiYy5jb20vbmV3cy92aWRlb3MvY3l4eG53dzI5MXpv0gEA?hl=en-US&gl=US&ceid=US%3Aen\n",
      "Error parsing article with newspaper3k: No content parsed by newspaper3k\n",
      "Attempting to manually extract content...\n",
      "getting content from url:  https://news.google.com/articles/CBMingFodHRwczovL3d3dy5pbmRpYS5jb20vbmV3cy93b3JsZC91cy10b3JuYWRvZXMtMjEtZGVhZC1hcy1wb3dlcmZ1bC1zdG9ybXMtcmlwcGVkLXRocm91Z2gtdGV4YXMtb2tsYWhvbWEtYXJrYW5zYXMtYW5kLWtlbnR1Y2t5LWhlcmVzLXdoYXQtd2Utbm93LXNvLWZhci02OTY3NDc3L9IBogFodHRwczovL3d3dy5pbmRpYS5jb20vbmV3cy93b3JsZC91cy10b3JuYWRvZXMtMjEtZGVhZC1hcy1wb3dlcmZ1bC1zdG9ybXMtcmlwcGVkLXRocm91Z2gtdGV4YXMtb2tsYWhvbWEtYXJrYW5zYXMtYW5kLWtlbnR1Y2t5LWhlcmVzLXdoYXQtd2Utbm93LXNvLWZhci02OTY3NDc3L2FtcC8?hl=en-US&gl=US&ceid=US%3Aen\n",
      "Error parsing article with newspaper3k: No content parsed by newspaper3k\n",
      "Attempting to manually extract content...\n",
      "getting content from url:  https://news.google.com/articles/CBMiZWh0dHBzOi8vd3d3LnZvYW5ld3MuY29tL2EvdGV4YXMtdG8tZmFjZS1tb3JlLWluY2xlbWVudC13ZWF0aGVyLWFmdGVyLW1lbW9yaWFsLWRheS1zdG9ybXMvNzYzMDQyNS5odG1s0gFnaHR0cHM6Ly93d3cudm9hbmV3cy5jb20vYW1wL3RleGFzLXRvLWZhY2UtbW9yZS1pbmNsZW1lbnQtd2VhdGhlci1hZnRlci1tZW1vcmlhbC1kYXktc3Rvcm1zLzc2MzA0MjUuaHRtbA?hl=en-US&gl=US&ceid=US%3Aen\n",
      "Error parsing article with newspaper3k: No content parsed by newspaper3k\n",
      "Attempting to manually extract content...\n",
      "getting content from url:  https://news.google.com/articles/CBMiYGh0dHBzOi8vd2VhdGhlci5jb20vc3Rvcm1zL3NldmVyZS92aWRlby9kZWFkbHktdG9ybmFkb2VzLWxlYXZlLWRhbWFnZS1pbi10ZXhhcy1hcmthbnNhcy1va2xhaG9tYdIBAA?hl=en-US&gl=US&ceid=US%3Aen\n",
      "Error parsing article with newspaper3k: No content parsed by newspaper3k\n",
      "Attempting to manually extract content...\n",
      "getting content from url:  https://news.google.com/articles/CBMiiwFodHRwczovL3d3dy5uZXdzbmF0aW9ubm93LmNvbS93ZWF0aGVyL2FwLWxhdGVzdC1kZWFkbHktd2VhdGhlci1pbi11cy1raWxscy1hdC1sZWFzdC0xOC1hcy1zdG9ybXMtY2FydmUtcGF0aC1vZi1ydWluLWFjcm9zcy1tdWx0aXBsZS1zdGF0ZXMv0gGPAWh0dHBzOi8vd3d3Lm5ld3NuYXRpb25ub3cuY29tL3dlYXRoZXIvYXAtbGF0ZXN0LWRlYWRseS13ZWF0aGVyLWluLXVzLWtpbGxzLWF0LWxlYXN0LTE4LWFzLXN0b3Jtcy1jYXJ2ZS1wYXRoLW9mLXJ1aW4tYWNyb3NzLW11bHRpcGxlLXN0YXRlcy9hbXAv?hl=en-US&gl=US&ceid=US%3Aen\n",
      "Error parsing article with newspaper3k: No content parsed by newspaper3k\n",
      "Attempting to manually extract content...\n",
      "getting content from url:  https://news.google.com/articles/CBMiVGh0dHBzOi8vdGhld2Vlay5jb20vZW52aXJvbm1lbnQvc2V2ZXJlLXdlYXRoZXItc3Rvcm1zLXRvcm5hZG9lcy1tZW1vcmlhbC1kYXktd2Vla2VuZNIBAA?hl=en-US&gl=US&ceid=US%3Aen\n",
      "Error parsing article with newspaper3k: No content parsed by newspaper3k\n",
      "Attempting to manually extract content...\n",
      "getting content from url:  https://news.google.com/articles/CBMiY2h0dHBzOi8vd3d3LnVzYXRvZGF5LmNvbS9zdG9yeS9uZXdzL25hdGlvbi8yMDI0LzA1LzI3L2tlbnR1Y2t5LXBvd2VyLW91dGFnZS1tZHctc3Rvcm1zLzczODY4NTQ0MDA3L9IBAA?hl=en-US&gl=US&ceid=US%3Aen\n",
      "Error parsing article with newspaper3k: No content parsed by newspaper3k\n",
      "Attempting to manually extract content...\n",
      "getting content from url:  https://news.google.com/articles/CBMiZ2h0dHBzOi8vd3d3LnJldXRlcnMuY29tL3dvcmxkL3VzL2tlbnR1Y2t5LXdhcm5zLW1vcmUtc2V2ZXJlLXdlYXRoZXItYWZ0ZXItdXMtc3Rvcm1zLWtpbGwtMTQtMjAyNC0wNS0yNy_SAQA?hl=en-US&gl=US&ceid=US%3Aen\n",
      "Error parsing article with newspaper3k: No content parsed by newspaper3k\n",
      "Attempting to manually extract content...\n",
      "getting content from url:  https://news.google.com/articles/CBMiZWh0dHBzOi8vd3d3LmluZGVwZW5kZW50LmNvLnVrL25ld3Mvd29ybGQvYW1lcmljYXMvc2V2ZXJlLXN0b3Jtcy10ZXhhcy1hcmthbnNhcy1va2xhaG9tYS1iMjU1MTc5NS5odG1s0gEA?hl=en-US&gl=US&ceid=US%3Aen\n",
      "Error parsing article with newspaper3k: No content parsed by newspaper3k\n",
      "Attempting to manually extract content...\n",
      "getting content from url:  https://news.google.com/articles/CBMilgFodHRwczovL3d3dy5uYmNuZXd5b3JrLmNvbS9uZXdzL25hdGlvbmFsLWludGVybmF0aW9uYWwvbmVhcmx5LTQwMDAwMC13aXRob3V0LXBvd2VyLWluLW1pc3NvdXJpLWFya2Fuc2FzLWtlbnR1Y2t5LWFzLXN0b3Jtcy1iYXR0ZXItY2VudHJhbC11LXMvNTQ0ODk2OC_SAZwBaHR0cHM6Ly93d3cubmJjbmV3eW9yay5jb20vbmV3cy9uYXRpb25hbC1pbnRlcm5hdGlvbmFsL25lYXJseS00MDAwMDAtd2l0aG91dC1wb3dlci1pbi1taXNzb3VyaS1hcmthbnNhcy1rZW50dWNreS1hcy1zdG9ybXMtYmF0dGVyLWNlbnRyYWwtdS1zLzU0NDg5NjgvP2FtcD0x?hl=en-US&gl=US&ceid=US%3Aen\n",
      "Error parsing article with newspaper3k: No content parsed by newspaper3k\n",
      "Attempting to manually extract content...\n",
      "getting content from url:  https://news.google.com/articles/CBMiZ2h0dHBzOi8vd3d3LnVzYXRvZGF5LmNvbS9zdG9yeS9uZXdzL3dlYXRoZXIvMjAyNC8wNS8yOS9pcy0yMDI0LWEtcmVjb3JkLXllYXItZm9yLXRvcm5hZG9lcy83Mzg3NTQ4MTAwNy_SAQA?hl=en-US&gl=US&ceid=US%3Aen\n",
      "Error parsing article with newspaper3k: No content parsed by newspaper3k\n",
      "Attempting to manually extract content...\n",
      "getting content from url:  https://news.google.com/articles/CBMiWmh0dHBzOi8vd3d3Lmh1ZmZwb3N0LmNvbS9lbnRyeS91cy1zZXZlcmUtd2VhdGhlci10ZXhhcy1va2xhaG9tYV9uXzY2NTI2MDcyZTRiMGNmNjljNGUzZmQxZdIBXmh0dHBzOi8vd3d3Lmh1ZmZwb3N0LmNvbS9lbnRyeS91cy1zZXZlcmUtd2VhdGhlci10ZXhhcy1va2xhaG9tYV9uXzY2NTI2MDcyZTRiMGNmNjljNGUzZmQxZS9hbXA?hl=en-US&gl=US&ceid=US%3Aen\n",
      "Error parsing article with newspaper3k: No content parsed by newspaper3k\n",
      "Attempting to manually extract content...\n",
      "getting content from url:  https://news.google.com/articles/CBMiY2h0dHBzOi8vd3d3Lm5ld3N3ZWVrLmNvbS92aWRlby1zaG93cy1kZWFkbHktdG9ybmFkby1kZXN0cm95LXRleGFzLWdhcy1zdGF0aW9uLXBlb3BsZS1pbnNpZGUtMTkwNDg2NdIBAA?hl=en-US&gl=US&ceid=US%3Aen\n",
      "Error parsing article with newspaper3k: No content parsed by newspaper3k\n",
      "Attempting to manually extract content...\n",
      "getting content from url:  https://news.google.com/articles/CBMiLmh0dHBzOi8vd3d3LmJiYy5jb20vbmV3cy9hcnRpY2xlcy9jeDg4MHg1OHdnMG_SATJodHRwczovL3d3dy5iYmMuY29tL25ld3MvYXJ0aWNsZXMvY3g4ODB4NTh3ZzBvLmFtcA?hl=en-US&gl=US&ceid=US%3Aen\n",
      "Error parsing article with newspaper3k: No content parsed by newspaper3k\n",
      "Attempting to manually extract content...\n",
      "getting content from url:  https://news.google.com/articles/CBMiVmh0dHBzOi8vd3d3LmNubi5jb20vMjAyNC8wNS8yNy93ZWF0aGVyL21lbW9yaWFsLWRheS13ZWVrZW5kLWZvcmVjYXN0LW1vbmRheS9pbmRleC5odG1s0gFPaHR0cHM6Ly9hbXAuY25uLmNvbS9jbm4vMjAyNC8wNS8yNy93ZWF0aGVyL21lbW9yaWFsLWRheS13ZWVrZW5kLWZvcmVjYXN0LW1vbmRheQ?hl=en-US&gl=US&ceid=US%3Aen\n",
      "Error parsing article with newspaper3k: No content parsed by newspaper3k\n",
      "Attempting to manually extract content...\n",
      "getting content from url:  https://news.google.com/articles/CBMiWGh0dHBzOi8vd3d3Lm5wci5vcmcvMjAyNC8wNS8yNy9ueC1zMS00OTgzMDk4L2Vhc3Rlcm4tdXMtd2VhdGhlci1mb3JlY2FzdC1zb3V0aC10b3JuYWRvZXPSAQA?hl=en-US&gl=US&ceid=US%3Aen\n",
      "Error parsing article with newspaper3k: No content parsed by newspaper3k\n",
      "Attempting to manually extract content...\n",
      "getting content from url:  https://news.google.com/articles/CBMimAFodHRwczovL3d3dy5hY2N1d2VhdGhlci5jb20vZW4vc2V2ZXJlLXdlYXRoZXIvYXQtbGVhc3QtMjItZGVhZC1kb3plbnMtaW5qdXJlZC1hcy1zdXNwZWN0ZWQtdG9ybmFkb2VzLWxlYXZlLXRyYWlsLW9mLWRlc3RydWN0aW9uLWFjcm9zcy10aGUtc291dGgvMTY1MzkzMNIBnAFodHRwczovL3d3dy5hY2N1d2VhdGhlci5jb20vZW4vc2V2ZXJlLXdlYXRoZXIvYXQtbGVhc3QtMjItZGVhZC1kb3plbnMtaW5qdXJlZC1hcy1zdXNwZWN0ZWQtdG9ybmFkb2VzLWxlYXZlLXRyYWlsLW9mLWRlc3RydWN0aW9uLWFjcm9zcy10aGUtc291dGgvMTY1MzkzMC9hbXA?hl=en-US&gl=US&ceid=US%3Aen\n",
      "Error parsing article with newspaper3k: No content parsed by newspaper3k\n",
      "Attempting to manually extract content...\n",
      "getting content from url:  https://news.google.com/articles/CBMiYmh0dHBzOi8vd3d3LmRhaWx5bWFpbC5jby51ay9uZXdzL2FydGljbGUtMTM0NjEzODkvbWVtb3JpYWwtZGF5LXdlZWtlbmQtdG9ybmFkby10ZXhhcy1va2xhaG9tYS5odG1s0gFmaHR0cHM6Ly93d3cuZGFpbHltYWlsLmNvLnVrL25ld3MvYXJ0aWNsZS0xMzQ2MTM4OS9hbXAvbWVtb3JpYWwtZGF5LXdlZWtlbmQtdG9ybmFkby10ZXhhcy1va2xhaG9tYS5odG1s?hl=en-US&gl=US&ceid=US%3Aen\n",
      "Error parsing article with newspaper3k: No content parsed by newspaper3k\n",
      "Attempting to manually extract content...\n",
      "getting content from url:  https://news.google.com/articles/CBMiYWh0dHBzOi8vd3d3LnNwb2tlc21hbi5jb20vc3Rvcmllcy8yMDI0L21heS8yNi9zdG9ybXMta2lsbC0xNC1pbi1taWR3ZXN0LWFzLXNldmVyZS13ZWF0aGVyLW1vdmVzLS_SAQA?hl=en-US&gl=US&ceid=US%3Aen\n",
      "Error parsing article with newspaper3k: No content parsed by newspaper3k\n",
      "Attempting to manually extract content...\n",
      "getting content from url:  https://news.google.com/articles/CBMiV2h0dHBzOi8vd3d3LmRpcmVjdHJlbGllZi5vcmcvMjAyNC8wNS9leHRyZW1lLXdlYXRoZXItYmF0dGVycy10aGUtdS1zLW1pZHdlc3QtYW5kLXNvdXRoL9IBW2h0dHBzOi8vd3d3LmRpcmVjdHJlbGllZi5vcmcvMjAyNC8wNS9leHRyZW1lLXdlYXRoZXItYmF0dGVycy10aGUtdS1zLW1pZHdlc3QtYW5kLXNvdXRoL2FtcC8?hl=en-US&gl=US&ceid=US%3Aen\n",
      "Error parsing article with newspaper3k: No content parsed by newspaper3k\n",
      "Attempting to manually extract content...\n",
      "getting content from url:  https://news.google.com/articles/CBMiSGh0dHBzOi8vd3d3LmZveHdlYXRoZXIuY29tL3dlYXRoZXItbmV3cy9kYWlseS13ZWF0aGVyLXVwZGF0ZS1tYXktMjgtMjAyNNIBTGh0dHBzOi8vd3d3LmZveHdlYXRoZXIuY29tL3dlYXRoZXItbmV3cy9kYWlseS13ZWF0aGVyLXVwZGF0ZS1tYXktMjgtMjAyNC5hbXA?hl=en-US&gl=US&ceid=US%3Aen\n",
      "Error parsing article with newspaper3k: No content parsed by newspaper3k\n",
      "Attempting to manually extract content...\n",
      "getting content from url:  https://news.google.com/articles/CBMidWh0dHBzOi8vd3d3LnN0cmFpdHN0aW1lcy5jb20vd29ybGQvdW5pdGVkLXN0YXRlcy9hdC1sZWFzdC0xNC1kZWFkLWZyb20tc3Rvcm1zLWluLXRleGFzLWFya2Fuc2FzLW9rbGFob21hLWFuZC1rZW50dWNredIBAA?hl=en-US&gl=US&ceid=US%3Aen\n",
      "Error parsing article with newspaper3k: No content parsed by newspaper3k\n",
      "Attempting to manually extract content...\n",
      "getting content from url:  https://news.google.com/articles/CBMiSGh0dHBzOi8vd3d3Lm5ld3N3ZWVrLmNvbS90b3JuYWRvcy1zdG9ybXMtcG93ZXItb3V0YWdlcy1ibGFja291dHMtMTkwNTAyONIBAA?hl=en-US&gl=US&ceid=US%3Aen\n",
      "Error parsing article with newspaper3k: No content parsed by newspaper3k\n",
      "Attempting to manually extract content...\n",
      "getting content from url:  https://news.google.com/articles/CBMivQFodHRwczovL3d3dy5rZ3cuY29tL2FydGljbGUvbmV3cy9uYXRpb24td29ybGQvYXQtbGVhc3QtMTUtZGVhZC1hZnRlci1zZXZlcmUtd2VhdGhlci1jYXJ2ZXMtcGF0aC1vZi1ydWluLWFjcm9zcy1tdWx0aXBsZS1zdGF0ZXMtaW4tdGhlLXNvdXRoLXR4LWFyLW9rLzUwNy0zODhjZDc2MC1jMjQ0LTQxNWQtODJlNS1iOTk5MjZhOTVjNjPSAQA?hl=en-US&gl=US&ceid=US%3Aen\n",
      "Error parsing article with newspaper3k: No content parsed by newspaper3k\n",
      "Attempting to manually extract content...\n",
      "getting content from url:  https://news.google.com/articles/CBMiYmh0dHBzOi8vd3d3LmZhc3Rjb21wYW55LmNvbS85MTEzMTg0Mi9tZW1vcmlhbC1kYXktd2Vla2VuZC1zZXZlcmUtd2VhdGhlci1raWxscy0yMC1zdG9ybXMtbW92ZS1lYXN00gEA?hl=en-US&gl=US&ceid=US%3Aen\n",
      "Error parsing article with newspaper3k: No content parsed by newspaper3k\n",
      "Attempting to manually extract content...\n",
      "getting content from url:  https://news.google.com/articles/CBMiVGh0dHBzOi8vd3d3LmtmZGkuY29tLzIwMjQvMDUvMjcvdG9ybmFkb2VzLXNldmVyZS1zdG9ybXMtaGl0LW9rbGFob21hLWFya2Fuc2FzLXRleGFzL9IBAA?hl=en-US&gl=US&ceid=US%3Aen\n",
      "Error parsing article with newspaper3k: No content parsed by newspaper3k\n",
      "Attempting to manually extract content...\n",
      "getting content from url:  https://news.google.com/articles/CBMiQWh0dHBzOi8vd3d3Lm55dGltZXMuY29tLzIwMjQvMDUvMjcvdXMvYXJrYW5zYXMtc3Rvcm1zLXJvZ2Vycy5odG1s0gEA?hl=en-US&gl=US&ceid=US%3Aen\n",
      "Error parsing article with newspaper3k: No content parsed by newspaper3k\n",
      "Attempting to manually extract content...\n",
      "getting content from url:  https://news.google.com/articles/CBMiUmh0dHBzOi8vd3d3LnRoZW1pcnJvci5jb20vbmV3cy91cy1uZXdzL3Rvcm5hZG8tdGV4YXMtb2tsYWhvbWEtYXJrYW5zYXMtZGVhZC01MDY4NzXSAVZodHRwczovL3d3dy50aGVtaXJyb3IuY29tL25ld3MvdXMtbmV3cy90b3JuYWRvLXRleGFzLW9rbGFob21hLWFya2Fuc2FzLWRlYWQtNTA2ODc1LmFtcA?hl=en-US&gl=US&ceid=US%3Aen\n",
      "Error parsing article with newspaper3k: No content parsed by newspaper3k\n",
      "Attempting to manually extract content...\n",
      "getting content from url:  https://news.google.com/articles/CBMiWGh0dHBzOi8vd3d3LmFya2Fuc2Fzb25saW5lLmNvbS9uZXdzLzIwMjQvbWF5LzI4L3N0b3Jtcy11cHNldC1ob2xpZGF5LXBsYW5zLWZvci1taWxsaW9ucy_SAQA?hl=en-US&gl=US&ceid=US%3Aen\n",
      "Error parsing article with newspaper3k: No content parsed by newspaper3k\n",
      "Attempting to manually extract content...\n",
      "getting content from url:  https://news.google.com/articles/CBMihwFodHRwczovL3d3dy5sYXRpbWVzLmNvbS93b3JsZC1uYXRpb24vc3RvcnkvMjAyNC0wNS0yNy9hdC1sZWFzdC0yMC1kZWFkLWluLW1lbW9yaWFsLWRheS13ZWVrZW5kLXN0b3Jtcy10aGF0LWRldmFzdGF0ZWQtc2V2ZXJhbC11cy1zdGF0ZXPSAQA?hl=en-US&gl=US&ceid=US%3Aen\n",
      "Error parsing article with newspaper3k: No content parsed by newspaper3k\n",
      "Attempting to manually extract content...\n",
      "getting content from url:  https://news.google.com/articles/CBMihAFodHRwczovL3d3dy5kYWlseXByZXNzLmNvbS8yMDI0LzA1LzI4L3N0b3Jtcy1sZWF2ZS13aWRlc3ByZWFkLW91dGFnZXMtYWNyb3NzLXRleGFzLWNsZWFudXAtY29udGludWVzLWFmdGVyLWRlYWRseS13ZWVrZW5kLWFjcm9zcy11cy_SAQA?hl=en-US&gl=US&ceid=US%3Aen\n",
      "Error parsing article with newspaper3k: No content parsed by newspaper3k\n",
      "Attempting to manually extract content...\n",
      "getting content from url:  https://news.google.com/articles/CBMifGh0dHBzOi8vZm94NDAuY29tL25ld3MvbmF0aW9uYWwvYXAtdXMtbmV3cy9hcC0yMi1hcmUtZGVhZC1hY3Jvc3MtdGhlLXVzLWFmdGVyLXdlZWtlbmQtdG9ybmFkb2VzLW1vcmUtc3Rvcm1zLW1heS1iZS1pbi1zdG9yZS_SAYABaHR0cHM6Ly9mb3g0MC5jb20vbmV3cy9uYXRpb25hbC9hcC11cy1uZXdzL2FwLTIyLWFyZS1kZWFkLWFjcm9zcy10aGUtdXMtYWZ0ZXItd2Vla2VuZC10b3JuYWRvZXMtbW9yZS1zdG9ybXMtbWF5LWJlLWluLXN0b3JlL2FtcC8?hl=en-US&gl=US&ceid=US%3Aen\n",
      "Error parsing article with newspaper3k: No content parsed by newspaper3k\n",
      "Attempting to manually extract content...\n",
      "getting content from url:  https://news.google.com/articles/CBMiZWh0dHBzOi8vbmV3cy5za3kuY29tL3N0b3J5L3Rvcm5hZG9lcy1sZWF2ZS10cmFpbC1vZi1kZWF0aC1hbmQtZGVzdHJ1Y3Rpb24tYWNyb3NzLXBhcnRzLW9mLXVzLTEzMTQzNjcz0gFpaHR0cHM6Ly9uZXdzLnNreS5jb20vc3RvcnkvYW1wL3Rvcm5hZG9lcy1sZWF2ZS10cmFpbC1vZi1kZWF0aC1hbmQtZGVzdHJ1Y3Rpb24tYWNyb3NzLXBhcnRzLW9mLXVzLTEzMTQzNjcz?hl=en-US&gl=US&ceid=US%3Aen\n",
      "Error parsing article with newspaper3k: No content parsed by newspaper3k\n",
      "Attempting to manually extract content...\n",
      "getting content from url:  https://news.google.com/articles/CBMilQFodHRwczovL3d3dy5jb25uZWN0ZWR0b2luZGlhLmNvbS90b3JuYWRvZXMta2lsbC0xOC10ZWFyaW5nLXRocm91Z2gtdGV4YXMtb2tsYWhvbWEtYW5kLWFya2Fuc2FzLXBvd2VyLW91dGFnZS1hZmZlY3RzLTQ3MGstcGVvcGxlLWluLXNldmVyYWwtdXMtc3RhdGVzL9IBAA?hl=en-US&gl=US&ceid=US%3Aen\n",
      "Error parsing article with newspaper3k: No content parsed by newspaper3k\n",
      "Attempting to manually extract content...\n",
      "getting content from url:  https://news.google.com/articles/CBMiUWh0dHBzOi8vd3d3Lm15am95b25saW5lLmNvbS90b3JuYWRvZXMtYW5kLXN0b3Jtcy1sZWF2ZS0xNS1kZWFkLWFjcm9zcy1jZW50cmFsLXVzL9IBAA?hl=en-US&gl=US&ceid=US%3Aen\n",
      "Error parsing article with newspaper3k: No content parsed by newspaper3k\n",
      "Attempting to manually extract content...\n",
      "getting content from url:  https://news.google.com/articles/CBMiamh0dHBzOi8vd2VhdGhlcm5ld3Nwb2ludC5jb20vMjAyNC8wNS8yNy9zZXZlcmUtd2VhdGhlci1leHBlY3RlZC10by1oaXQtZWFzdGVybi11cy1mb2xsb3dpbmctZGVhZGx5LXN0b3Jtcy_SAQA?hl=en-US&gl=US&ceid=US%3Aen\n"
     ]
    }
   ],
   "source": [
    "# Prepare CSV file\n",
    "with open('newsarticles.csv', mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Event\", \"Event Date\", \"Article Date\", \"Article Publishers\", \"Article URL\", \"Article Content\"])\n",
    "\n",
    "    for event in news_events.to_dict(orient='records')[:1]:\n",
    "        keywords = generate_keywords(event)\n",
    "        start_date, end_date = get_date_range(event['Time'])\n",
    "        print(f\"Searching for news articles for event '{event['Event']}' between {start_date} and {end_date}\")\n",
    "        articles = search_news(keywords, start_date, end_date)\n",
    "        for article_url in articles:\n",
    "            try:\n",
    "                article_date, article_publishers, article_url, article_content = get_article_details(article_url)\n",
    "                writer.writerow([event['Event'], event['Time'], article_date, article_publishers, article_url, article_content])\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to fetch article from {article_url}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_url = 'https://news.google.com/search?q=%28people%2C%20Oklahoma%20OR%20Arkansas%2C%20Texas%2C%20Kentucky%29%20AND%20%28Tornadoes%20OR%20strike%29%20after:2024-05-19%20before:2024-06-18'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for news with URL: https://news.google.com/search?q=%28people%2C%20Oklahoma%20OR%20Arkansas%2C%20Texas%2C%20Kentucky%29%20AND%20%28Tornadoes%20OR%20strike%29%20after:2024-05-19%20before:2024-06-18\n"
     ]
    }
   ],
   "source": [
    "articles = []\n",
    "\n",
    "while search_url:\n",
    "    print(f\"Searching for news with URL: {search_url}\")\n",
    "    response = requests.get(search_url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    for link in soup.find_all('a', class_='WwrzSb'):\n",
    "        url = link.get('href')\n",
    "        if url and url.startswith('./articles/'):\n",
    "            full_url = f\"https://news.google.com{url[1:]}\"\n",
    "            articles.append(full_url)\n",
    "\n",
    "    next_button = soup.find('a', class_='nBDE1b G5eFlf')\n",
    "    search_url = f\"https://news.google.com{next_button['href'][1:]}\" if next_button else None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None,\n",
       " 'https://news.google.com',\n",
       " 'https://news.google.com/articles/CBMibmh0dHBzOi8vYXBuZXdzLmNvbS9hcnRpY2xlL3Rvcm5hZG9lcy13ZWF0aGVyLXRleGFzLW9rbGFob21hLWFya2Fuc2FzLWtlbnR1Y2t5LTkxYjBmZjVjMDZmOWJkYzhiOGNhNjhmMzZhZmJhZmEy0gEA?hl=en-US&gl=US&ceid=US%3Aen',\n",
       " '')"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article = Article('https://news.google.com/articles/CBMibmh0dHBzOi8vYXBuZXdzLmNvbS9hcnRpY2xlL3Rvcm5hZG9lcy13ZWF0aGVyLXRleGFzLW9rbGFob21hLWFya2Fuc2FzLWtlbnR1Y2t5LTkxYjBmZjVjMDZmOWJkYzhiOGNhNjhmMzZhZmJhZmEy0gEA?hl=en-US&gl=US&ceid=US%3Aen')\n",
    "article.download()\n",
    "article.parse()\n",
    "article.publish_date, article.source_url, article.url, article.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(articles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "try serpi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = '66ac47018bbaa4304deef8e4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_news(keywords, start_date, end_date, num_results=10, num_pages=5):\n",
    "    articles = []\n",
    "    for page in range(0, num_pages * num_results, num_results):\n",
    "        payload = {\n",
    "            'api_key': '66ac47018bbaa4304deef8e4',\n",
    "            'q': keywords,\n",
    "            'gl': 'us',\n",
    "            'hl': 'en_us',\n",
    "            'from': start_date,\n",
    "            'to': end_date,\n",
    "            'num': num_results,\n",
    "            'start': page\n",
    "        }\n",
    "        resp = requests.get('https://api.serpdog.io/news', params=payload)\n",
    "        if resp.status_code == 200:\n",
    "            articles.extend(resp.json().get('news_results', []))\n",
    "        else:\n",
    "            print(f\"Error fetching page {page // num_results + 1}: {resp.status_code}\")\n",
    "            break\n",
    "    return articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for news articles for event 'Tornadoes strike Oklahoma, Texas, Arkansas, and Kentucky, killing 21 people' between 2024-05-19 and 2024-06-18\n",
      "Done writing to CSV file.\n"
     ]
    }
   ],
   "source": [
    "with open('news_results1.csv', mode='w', newline='', encoding='utf-8') as csvfile:\n",
    "    csv_writer = csv.writer(csvfile)\n",
    "    # Write the headers\n",
    "    csv_writer.writerow([\"Event\", \"Event Date\", \"title\", \"snippet\", \"source\", \"lastUpdated\", \"url\"])\n",
    "\n",
    "    for event in news_events.to_dict(orient='records')[:1]:\n",
    "        keywords = generate_keywords(event)\n",
    "        start_date, end_date = get_date_range(event['Time'])\n",
    "        print(f\"Searching for news articles for event '{event['Event']}' between {start_date} and {end_date}\")\n",
    "        news_results = search_news(keywords, start_date, end_date)\n",
    "        \n",
    "        # Write the data\n",
    "        for result in news_results:\n",
    "            csv_writer.writerow([event['Event'], event['Time'], result[\"title\"], result[\"snippet\"], result[\"source\"], result[\"lastUpdated\"], result[\"url\"]])\n",
    "        \n",
    "print('Done writing to CSV file.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for news articles for event 'Boeing's Starliner capsule launches its first astronaut-crewed flight into space to the International Space Station after several delays at the Cape Canaveral Space Force Station in Florida.' between 2024-06-05 and 2024-07-05\n",
      "Done writing to CSV file.\n"
     ]
    }
   ],
   "source": [
    "with open('news_results2.csv', mode='w', newline='', encoding='utf-8') as csvfile:\n",
    "    csv_writer = csv.writer(csvfile)\n",
    "    # Write the headers\n",
    "    csv_writer.writerow([\"Event\", \"Event Date\", \"title\", \"snippet\", \"source\", \"lastUpdated\", \"url\"])\n",
    "\n",
    "    for event in news_events.to_dict(orient='records')[1:2]:\n",
    "        keywords = generate_keywords(event)\n",
    "        start_date, end_date = get_date_range(event['Time'])\n",
    "        print(f\"Searching for news articles for event '{event['Event']}' between {start_date} and {end_date}\")\n",
    "        news_results = search_news(keywords, start_date, end_date)\n",
    "        \n",
    "        # Write the data\n",
    "        for result in news_results:\n",
    "            csv_writer.writerow([event['Event'], event['Time'], result[\"title\"], result[\"snippet\"], result[\"source\"], result[\"lastUpdated\"], result[\"url\"]])\n",
    "        \n",
    "print('Done writing to CSV file.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for news articles for event 'The Biden administration released revisions to Title IX rules which give further protections for LGBTQ+ students as well as parenting and pregnant students.' between 2024-04-19 and 2024-05-19\n",
      "Done writing to CSV file.\n"
     ]
    }
   ],
   "source": [
    "with open('news_results3.csv', mode='w', newline='', encoding='utf-8') as csvfile:\n",
    "    csv_writer = csv.writer(csvfile)\n",
    "    # Write the headers\n",
    "    csv_writer.writerow([\"Event\", \"Event Date\", \"title\", \"snippet\", \"source\", \"lastUpdated\", \"url\"])\n",
    "\n",
    "    for event in news_events.to_dict(orient='records')[2:3]:\n",
    "        keywords = generate_keywords(event)\n",
    "        start_date, end_date = get_date_range(event['Time'])\n",
    "        print(f\"Searching for news articles for event '{event['Event']}' between {start_date} and {end_date}\")\n",
    "        news_results = search_news(keywords, start_date, end_date)\n",
    "        \n",
    "        # Write the data\n",
    "        for result in news_results:\n",
    "            csv_writer.writerow([event['Event'], event['Time'], result[\"title\"], result[\"snippet\"], result[\"source\"], result[\"lastUpdated\"], result[\"url\"]])\n",
    "        \n",
    "print('Done writing to CSV file.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for news articles for event 'In Planned Parenthood Arizona v. Mayes, the Arizona Supreme Court upholds an 1864 law that disallows most types of abortions' between 2024-04-09 and 2024-05-09\n",
      "Done writing to CSV file.\n"
     ]
    }
   ],
   "source": [
    "with open('news_results4.csv', mode='w', newline='', encoding='utf-8') as csvfile:\n",
    "    csv_writer = csv.writer(csvfile)\n",
    "    # Write the headers\n",
    "    csv_writer.writerow([\"Event\", \"Event Date\", \"title\", \"snippet\", \"source\", \"lastUpdated\", \"url\"])\n",
    "\n",
    "    for event in news_events.to_dict(orient='records')[3:4]:\n",
    "        keywords = generate_keywords(event)\n",
    "        start_date, end_date = get_date_range(event['Time'])\n",
    "        print(f\"Searching for news articles for event '{event['Event']}' between {start_date} and {end_date}\")\n",
    "        news_results = search_news(keywords, start_date, end_date)\n",
    "        \n",
    "        # Write the data\n",
    "        for result in news_results:\n",
    "            csv_writer.writerow([event['Event'], event['Time'], result[\"title\"], result[\"snippet\"], result[\"source\"], result[\"lastUpdated\"], result[\"url\"]])\n",
    "        \n",
    "print('Done writing to CSV file.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Content scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to scrape news content from the given URL\n",
    "def get_content(url):\n",
    "    session = requests.Session()\n",
    "    response = session.get(url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "    print('Getting content from URL:', url)\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        print('Error with request')\n",
    "        html = ''\n",
    "    else:\n",
    "        html = response.content\n",
    "\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    div_tag = soup.find_all('div', class_='article-body')\n",
    "    div_tag2 = soup.find_all('div', class_='article-content')\n",
    "    div_tag3 = soup.find_all('p', class_='gnt_ar_b_p')  # USA Today\n",
    "    div_tag4 = soup.find_all('div', class_='article__text | body-copy | flow')  # The Hill\n",
    "    div_tag5 = soup.find_all('div', class_='primary-cli cli cli-text')\n",
    "\n",
    "    if div_tag:\n",
    "        return collect_content(div_tag)\n",
    "    elif div_tag2:\n",
    "        return collect_content(div_tag2)\n",
    "    elif div_tag3:\n",
    "        return collect_content_USA(div_tag3)\n",
    "    elif div_tag4:\n",
    "        return collect_content(div_tag4)\n",
    "    elif div_tag5:\n",
    "        return collect_content(div_tag5)\n",
    "    else:\n",
    "        c_list = [v.text for v in soup.find_all('p') if len(v.text) > 0]\n",
    "        words_to_bans = ['<', 'javascript']\n",
    "        for word_to_ban in words_to_bans:\n",
    "            c_list = list(filter(lambda x: word_to_ban not in x.lower(), c_list))\n",
    "        c_list = [t for t in c_list if len(re.findall('[a-z]', t.lower())) / (len(t) + 1) < 0.8]\n",
    "        content = ' '.join(c_list)\n",
    "        content = content.replace('\\n', ' ')\n",
    "        content = re.sub('\\s\\s+', ' ', content)  # remove multiple spaces.\n",
    "        return content\n",
    "\n",
    "def collect_content(tag_list):\n",
    "    return ' '.join([tag.get_text() for tag in tag_list])\n",
    "\n",
    "def collect_content_USA(tag_list):\n",
    "    return ' '.join([tag.get_text() for tag in tag_list])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting content from URL: https://apnews.com/article/tornadoes-weather-texas-oklahoma-arkansas-kentucky-91b0ff5c06f9bdc8b8ca68f36afbafa2\n",
      "Getting content from URL: https://www.npr.org/2024/05/26/g-s1-1092/tornadoes-texas-oklahoma-arkansas\n",
      "Getting content from URL: https://www.cnn.com/weather/live-news/oklahoma-texas-arkansas-tornado-storms-05-27-24-intl-hnk/index.html\n",
      "Getting content from URL: https://www.wgbh.org/news/2024-05-26/more-than-20-are-dead-after-tornadoes-rip-through-parts-of-texas-kentucky-arkansas\n",
      "Getting content from URL: https://www.nytimes.com/2024/05/26/us/tornadoes-storms-texas-oklahoma.html\n",
      "Error with request\n",
      "Getting content from URL: https://weather.com/news/weather/news/2024-05-25-deadly-tornado-texas-oklahoma-arkansas-storms\n",
      "Getting content from URL: https://www.cbsnews.com/news/storms-kill-at-least-19-texas-kentucky-arkansas-oklahoma/\n",
      "Getting content from URL: https://www.reuters.com/world/us/tornadoes-hit-texas-arkansas-oklahoma-killing-least-2-texas-nyt-reports-2024-05-26/\n",
      "Error with request\n",
      "Getting content from URL: https://www.usatoday.com/story/news/nation/2024/05/26/texas-oklahoma-tornado-severe-weather-live-updates/73861776007/\n",
      "Getting content from URL: https://www.bbc.com/news/articles/cxxxp1w6e2ro\n",
      "Getting content from URL: https://apnews.com/article/tornadoes-weather-texas-oklahoma-arkansas-kentucky-91b0ff5c06f9bdc8b8ca68f36afbafa2\n",
      "Getting content from URL: https://www.npr.org/2024/05/26/g-s1-1092/tornadoes-texas-oklahoma-arkansas\n",
      "Getting content from URL: https://www.cnn.com/weather/live-news/oklahoma-texas-arkansas-tornado-storms-05-27-24-intl-hnk/index.html\n",
      "Getting content from URL: https://www.wgbh.org/news/2024-05-26/more-than-20-are-dead-after-tornadoes-rip-through-parts-of-texas-kentucky-arkansas\n",
      "Getting content from URL: https://www.nytimes.com/2024/05/26/us/tornadoes-storms-texas-oklahoma.html\n",
      "Error with request\n",
      "Getting content from URL: https://weather.com/news/weather/news/2024-05-25-deadly-tornado-texas-oklahoma-arkansas-storms\n",
      "Getting content from URL: https://www.cbsnews.com/news/storms-kill-at-least-19-texas-kentucky-arkansas-oklahoma/\n",
      "Getting content from URL: https://www.reuters.com/world/us/tornadoes-hit-texas-arkansas-oklahoma-killing-least-2-texas-nyt-reports-2024-05-26/\n",
      "Error with request\n",
      "Getting content from URL: https://www.usatoday.com/story/news/nation/2024/05/26/texas-oklahoma-tornado-severe-weather-live-updates/73861776007/\n",
      "Getting content from URL: https://www.bbc.com/news/articles/cxxxp1w6e2ro\n",
      "Getting content from URL: https://apnews.com/article/tornadoes-weather-texas-oklahoma-arkansas-kentucky-91b0ff5c06f9bdc8b8ca68f36afbafa2\n",
      "Getting content from URL: https://www.npr.org/2024/05/26/g-s1-1092/tornadoes-texas-oklahoma-arkansas\n",
      "Getting content from URL: https://www.cnn.com/weather/live-news/oklahoma-texas-arkansas-tornado-storms-05-27-24-intl-hnk/index.html\n",
      "Getting content from URL: https://www.wgbh.org/news/2024-05-26/more-than-20-are-dead-after-tornadoes-rip-through-parts-of-texas-kentucky-arkansas\n",
      "Getting content from URL: https://www.nytimes.com/2024/05/26/us/tornadoes-storms-texas-oklahoma.html\n",
      "Error with request\n",
      "Getting content from URL: https://weather.com/news/weather/news/2024-05-25-deadly-tornado-texas-oklahoma-arkansas-storms\n",
      "Getting content from URL: https://www.cbsnews.com/news/storms-kill-at-least-19-texas-kentucky-arkansas-oklahoma/\n",
      "Getting content from URL: https://www.reuters.com/world/us/tornadoes-hit-texas-arkansas-oklahoma-killing-least-2-texas-nyt-reports-2024-05-26/\n",
      "Error with request\n",
      "Getting content from URL: https://www.usatoday.com/story/news/nation/2024/05/26/texas-oklahoma-tornado-severe-weather-live-updates/73861776007/\n",
      "Getting content from URL: https://www.bbc.com/news/articles/cxxxp1w6e2ro\n",
      "Getting content from URL: https://apnews.com/article/tornadoes-weather-texas-oklahoma-arkansas-kentucky-91b0ff5c06f9bdc8b8ca68f36afbafa2\n",
      "Getting content from URL: https://www.npr.org/2024/05/26/g-s1-1092/tornadoes-texas-oklahoma-arkansas\n",
      "Getting content from URL: https://www.cnn.com/weather/live-news/oklahoma-texas-arkansas-tornado-storms-05-27-24-intl-hnk/index.html\n",
      "Getting content from URL: https://www.wgbh.org/news/2024-05-26/more-than-20-are-dead-after-tornadoes-rip-through-parts-of-texas-kentucky-arkansas\n",
      "Getting content from URL: https://www.nytimes.com/2024/05/26/us/tornadoes-storms-texas-oklahoma.html\n",
      "Error with request\n",
      "Getting content from URL: https://weather.com/news/weather/news/2024-05-25-deadly-tornado-texas-oklahoma-arkansas-storms\n",
      "Getting content from URL: https://www.cbsnews.com/news/storms-kill-at-least-19-texas-kentucky-arkansas-oklahoma/\n",
      "Getting content from URL: https://www.reuters.com/world/us/tornadoes-hit-texas-arkansas-oklahoma-killing-least-2-texas-nyt-reports-2024-05-26/\n",
      "Error with request\n",
      "Getting content from URL: https://www.usatoday.com/story/news/nation/2024/05/26/texas-oklahoma-tornado-severe-weather-live-updates/73861776007/\n",
      "Getting content from URL: https://www.bbc.com/news/articles/cxxxp1w6e2ro\n",
      "Getting content from URL: https://apnews.com/article/tornadoes-weather-texas-oklahoma-arkansas-kentucky-91b0ff5c06f9bdc8b8ca68f36afbafa2\n",
      "Getting content from URL: https://www.npr.org/2024/05/26/g-s1-1092/tornadoes-texas-oklahoma-arkansas\n",
      "Getting content from URL: https://www.cnn.com/weather/live-news/oklahoma-texas-arkansas-tornado-storms-05-27-24-intl-hnk/index.html\n",
      "Getting content from URL: https://www.wgbh.org/news/2024-05-26/more-than-20-are-dead-after-tornadoes-rip-through-parts-of-texas-kentucky-arkansas\n",
      "Getting content from URL: https://www.nytimes.com/2024/05/26/us/tornadoes-storms-texas-oklahoma.html\n",
      "Error with request\n",
      "Getting content from URL: https://weather.com/news/weather/news/2024-05-25-deadly-tornado-texas-oklahoma-arkansas-storms\n",
      "Getting content from URL: https://www.cbsnews.com/news/storms-kill-at-least-19-texas-kentucky-arkansas-oklahoma/\n",
      "Getting content from URL: https://www.reuters.com/world/us/tornadoes-hit-texas-arkansas-oklahoma-killing-least-2-texas-nyt-reports-2024-05-26/\n",
      "Error with request\n",
      "Getting content from URL: https://www.usatoday.com/story/news/nation/2024/05/26/texas-oklahoma-tornado-severe-weather-live-updates/73861776007/\n",
      "Getting content from URL: https://www.bbc.com/news/articles/cxxxp1w6e2ro\n"
     ]
    }
   ],
   "source": [
    "# Read the existing CSV to get the list of URLs and other information\n",
    "event1 = pd.read_csv('news_results1.csv')\n",
    "\n",
    "# Add a new column for the content\n",
    "event1['content'] = ''\n",
    "\n",
    "# Loop through each row to get content for each URL\n",
    "for index, row in event1.iterrows():\n",
    "    url = row['url']\n",
    "    content = get_content(url)\n",
    "    event1.at[index, 'content'] = content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop empty content\n",
    "event1.drop(event1[event1['content'] == ''].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "event2 = pd.read_csv('news_results2.csv')\n",
    "event3 = pd.read_csv('news_results3.csv')\n",
    "event4 = pd.read_csv('news_results4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_content_to_event(event):\n",
    "    # Add a new column for the content\n",
    "    event['content'] = ''\n",
    "\n",
    "    # Loop through each row to get content for each URL\n",
    "    for index, row in event.iterrows():\n",
    "        url = row['url']\n",
    "        content = get_content(url)\n",
    "        event.at[index, 'content'] = content\n",
    "    return event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting content from URL: https://www.livescience.com/space/space-exploration/boeing-starliner-astronauts-remain-stuck-on-international-space-station-with-no-set-return-date-nasa-announces\n",
      "Getting content from URL: https://abcnews.go.com/US/boeings-starliner-set-1st-astronaut-crewed-flight-after/story?id=110855655\n",
      "Getting content from URL: https://www.nbcnews.com/science/space/live-blog/live-updates-boeing-starliner-launch-nasa-astronauts-space-rcna155185\n",
      "Getting content from URL: https://www.npr.org/2024/06/05/nx-s1-4956024/boeing-starliner-launch-nasa-international-space-station\n",
      "Getting content from URL: https://www.latimes.com/business/story/2024-07-25/nasa-boeing-starliner-international-space-station-thrusters-helium-leak\n",
      "Getting content from URL: https://www.aljazeera.com/news/2024/6/27/why-are-two-boeing-astronauts-stuck-in-space\n",
      "Getting content from URL: https://www.mysanantonio.com/news/local/article/boeing-starliner-19581736.php\n",
      "Getting content from URL: https://www.reuters.com/technology/space/boeings-starliner-capsule-set-docking-with-space-station-2024-06-06/\n",
      "Error with request\n",
      "Getting content from URL: https://www.nasa.gov/news-release/liftoff-nasa-astronauts-pilot-first-starliner-crewed-test-to-station/\n",
      "Getting content from URL: https://www.space.com/boeing-starliner-astronaut-launch-abort-minutes-before-liftoff\n",
      "Getting content from URL: https://abcnews.go.com/US/boeings-starliner-set-1st-astronaut-crewed-flight-after/story?id=110855655\n",
      "Getting content from URL: https://www.livescience.com/space/space-exploration/boeing-starliner-astronauts-remain-stuck-on-international-space-station-with-no-set-return-date-nasa-announces\n",
      "Getting content from URL: https://www.nbcnews.com/science/space/live-blog/live-updates-boeing-starliner-launch-nasa-astronauts-space-rcna155185\n",
      "Getting content from URL: https://www.npr.org/2024/06/05/nx-s1-4956024/boeing-starliner-launch-nasa-international-space-station\n",
      "Getting content from URL: https://www.aljazeera.com/news/2024/6/27/why-are-two-boeing-astronauts-stuck-in-space\n",
      "Getting content from URL: https://www.latimes.com/business/story/2024-07-25/nasa-boeing-starliner-international-space-station-thrusters-helium-leak\n",
      "Getting content from URL: https://www.mysanantonio.com/news/local/article/boeing-starliner-19581736.php\n",
      "Getting content from URL: https://www.reuters.com/technology/space/boeings-starliner-capsule-set-docking-with-space-station-2024-06-06/\n",
      "Error with request\n",
      "Getting content from URL: https://www.space.com/boeing-starliner-astronaut-launch-abort-minutes-before-liftoff\n",
      "Getting content from URL: https://www.nasa.gov/news-release/liftoff-nasa-astronauts-pilot-first-starliner-crewed-test-to-station/\n",
      "Getting content from URL: https://www.livescience.com/space/space-exploration/boeing-starliner-astronauts-remain-stuck-on-international-space-station-with-no-set-return-date-nasa-announces\n",
      "Getting content from URL: https://abcnews.go.com/US/boeings-starliner-set-1st-astronaut-crewed-flight-after/story?id=110855655\n",
      "Getting content from URL: https://www.nbcnews.com/science/space/live-blog/live-updates-boeing-starliner-launch-nasa-astronauts-space-rcna155185\n",
      "Getting content from URL: https://www.npr.org/2024/06/05/nx-s1-4956024/boeing-starliner-launch-nasa-international-space-station\n",
      "Getting content from URL: https://www.latimes.com/business/story/2024-07-25/nasa-boeing-starliner-international-space-station-thrusters-helium-leak\n",
      "Getting content from URL: https://www.aljazeera.com/news/2024/6/27/why-are-two-boeing-astronauts-stuck-in-space\n",
      "Getting content from URL: https://www.mysanantonio.com/news/local/article/boeing-starliner-19581736.php\n",
      "Getting content from URL: https://www.reuters.com/technology/space/boeings-starliner-capsule-set-docking-with-space-station-2024-06-06/\n",
      "Error with request\n",
      "Getting content from URL: https://www.nasa.gov/news-release/liftoff-nasa-astronauts-pilot-first-starliner-crewed-test-to-station/\n",
      "Getting content from URL: https://www.space.com/boeing-starliner-astronaut-launch-abort-minutes-before-liftoff\n",
      "Getting content from URL: https://www.livescience.com/space/space-exploration/boeing-starliner-astronauts-remain-stuck-on-international-space-station-with-no-set-return-date-nasa-announces\n",
      "Getting content from URL: https://abcnews.go.com/US/boeings-starliner-set-1st-astronaut-crewed-flight-after/story?id=110855655\n",
      "Getting content from URL: https://www.nbcnews.com/science/space/live-blog/live-updates-boeing-starliner-launch-nasa-astronauts-space-rcna155185\n",
      "Getting content from URL: https://www.npr.org/2024/06/05/nx-s1-4956024/boeing-starliner-launch-nasa-international-space-station\n",
      "Getting content from URL: https://www.latimes.com/business/story/2024-07-25/nasa-boeing-starliner-international-space-station-thrusters-helium-leak\n",
      "Getting content from URL: https://www.aljazeera.com/news/2024/6/27/why-are-two-boeing-astronauts-stuck-in-space\n",
      "Getting content from URL: https://www.mysanantonio.com/news/local/article/boeing-starliner-19581736.php\n",
      "Getting content from URL: https://www.reuters.com/technology/space/boeings-starliner-capsule-set-docking-with-space-station-2024-06-06/\n",
      "Error with request\n",
      "Getting content from URL: https://www.nasa.gov/news-release/liftoff-nasa-astronauts-pilot-first-starliner-crewed-test-to-station/\n",
      "Getting content from URL: https://www.space.com/boeing-starliner-astronaut-launch-abort-minutes-before-liftoff\n",
      "Getting content from URL: https://www.livescience.com/space/space-exploration/boeing-starliner-astronauts-remain-stuck-on-international-space-station-with-no-set-return-date-nasa-announces\n",
      "Getting content from URL: https://abcnews.go.com/US/boeings-starliner-set-1st-astronaut-crewed-flight-after/story?id=110855655\n",
      "Getting content from URL: https://www.nbcnews.com/science/space/live-blog/live-updates-boeing-starliner-launch-nasa-astronauts-space-rcna155185\n",
      "Getting content from URL: https://www.npr.org/2024/06/05/nx-s1-4956024/boeing-starliner-launch-nasa-international-space-station\n",
      "Getting content from URL: https://www.latimes.com/business/story/2024-07-25/nasa-boeing-starliner-international-space-station-thrusters-helium-leak\n",
      "Getting content from URL: https://www.aljazeera.com/news/2024/6/27/why-are-two-boeing-astronauts-stuck-in-space\n",
      "Getting content from URL: https://www.mysanantonio.com/news/local/article/boeing-starliner-19581736.php\n",
      "Getting content from URL: https://www.reuters.com/technology/space/boeings-starliner-capsule-set-docking-with-space-station-2024-06-06/\n",
      "Error with request\n",
      "Getting content from URL: https://www.nasa.gov/news-release/liftoff-nasa-astronauts-pilot-first-starliner-crewed-test-to-station/\n",
      "Getting content from URL: https://www.space.com/boeing-starliner-astronaut-launch-abort-minutes-before-liftoff\n",
      "Getting content from URL: https://www.usatoday.com/story/news/nation/2024/08/01/biden-title-ix-rules-stalled-state-challenges/74530041007/\n",
      "Getting content from URL: https://www.insidehighered.com/news/government/2024/08/01/how-legal-challenges-tied-title-ix-26-states\n",
      "Getting content from URL: https://www.nytimes.com/2024/08/01/us/politics/biden-title-ix-gender-sex-discrimination.html\n",
      "Error with request\n",
      "Getting content from URL: https://scdailygazette.com/briefs/court-ruling-blocks-new-title-ix-rules-in-schools-colleges-across-sc/\n",
      "Getting content from URL: https://www.keranews.org/education/2024-08-01/title-ix-changes-expanding-lgbtq-protections-go-into-effect-but-not-in-texas\n",
      "Getting content from URL: https://www.wbrz.com/news/biden-administration-policy-expanding-title-ix-protections-to-lgbtq-students-take-effect/\n",
      "Getting content from URL: https://www.universityherald.com/articles/79156/20240801/biden-title-ix-overhaul-college-gender-identity-sex-discrimination-trump-transgender.htm\n",
      "Getting content from URL: https://www.foxnews.com/opinion/biden-harris-4-most-dangerous-title-ix-changes-girls\n",
      "Getting content from URL: https://www.politico.com/news/2024/07/30/biden-title-ix-policies-schools-00171797\n",
      "Error with request\n",
      "Getting content from URL: https://www.edweek.org/policy-politics/bidens-title-ix-rule-takes-effect-amid-a-confusing-legal-landscape/2024/07\n",
      "Getting content from URL: https://www.usatoday.com/story/news/nation/2024/08/01/biden-title-ix-rules-stalled-state-challenges/74530041007/\n",
      "Getting content from URL: https://www.insidehighered.com/news/government/2024/08/01/how-legal-challenges-tied-title-ix-26-states\n",
      "Getting content from URL: https://www.nytimes.com/2024/08/01/us/politics/biden-title-ix-gender-sex-discrimination.html\n",
      "Error with request\n",
      "Getting content from URL: https://scdailygazette.com/briefs/court-ruling-blocks-new-title-ix-rules-in-schools-colleges-across-sc/\n",
      "Getting content from URL: https://www.keranews.org/education/2024-08-01/title-ix-changes-expanding-lgbtq-protections-go-into-effect-but-not-in-texas\n",
      "Getting content from URL: https://www.wbrz.com/news/biden-administration-policy-expanding-title-ix-protections-to-lgbtq-students-take-effect/\n",
      "Getting content from URL: https://www.universityherald.com/articles/79156/20240801/biden-title-ix-overhaul-college-gender-identity-sex-discrimination-trump-transgender.htm\n",
      "Getting content from URL: https://www.foxnews.com/opinion/biden-harris-4-most-dangerous-title-ix-changes-girls\n",
      "Getting content from URL: https://www.politico.com/news/2024/07/30/biden-title-ix-policies-schools-00171797\n",
      "Error with request\n",
      "Getting content from URL: https://www.edweek.org/policy-politics/bidens-title-ix-rule-takes-effect-amid-a-confusing-legal-landscape/2024/07\n",
      "Getting content from URL: https://www.usatoday.com/story/news/nation/2024/08/01/biden-title-ix-rules-stalled-state-challenges/74530041007/\n",
      "Getting content from URL: https://www.insidehighered.com/news/government/2024/08/01/how-legal-challenges-tied-title-ix-26-states\n",
      "Getting content from URL: https://www.nytimes.com/2024/08/01/us/politics/biden-title-ix-gender-sex-discrimination.html\n",
      "Error with request\n",
      "Getting content from URL: https://scdailygazette.com/briefs/court-ruling-blocks-new-title-ix-rules-in-schools-colleges-across-sc/\n",
      "Getting content from URL: https://www.keranews.org/education/2024-08-01/title-ix-changes-expanding-lgbtq-protections-go-into-effect-but-not-in-texas\n",
      "Getting content from URL: https://www.wbrz.com/news/biden-administration-policy-expanding-title-ix-protections-to-lgbtq-students-take-effect/\n",
      "Getting content from URL: https://www.universityherald.com/articles/79156/20240801/biden-title-ix-overhaul-college-gender-identity-sex-discrimination-trump-transgender.htm\n",
      "Getting content from URL: https://www.foxnews.com/opinion/biden-harris-4-most-dangerous-title-ix-changes-girls\n",
      "Getting content from URL: https://www.politico.com/news/2024/07/30/biden-title-ix-policies-schools-00171797\n",
      "Error with request\n",
      "Getting content from URL: https://www.edweek.org/policy-politics/bidens-title-ix-rule-takes-effect-amid-a-confusing-legal-landscape/2024/07\n",
      "Getting content from URL: https://www.usatoday.com/story/news/nation/2024/08/01/biden-title-ix-rules-stalled-state-challenges/74530041007/\n",
      "Getting content from URL: https://www.insidehighered.com/news/government/2024/08/01/how-legal-challenges-tied-title-ix-26-states\n",
      "Getting content from URL: https://www.nytimes.com/2024/08/01/us/politics/biden-title-ix-gender-sex-discrimination.html\n",
      "Error with request\n",
      "Getting content from URL: https://scdailygazette.com/briefs/court-ruling-blocks-new-title-ix-rules-in-schools-colleges-across-sc/\n",
      "Getting content from URL: https://www.keranews.org/education/2024-08-01/title-ix-changes-expanding-lgbtq-protections-go-into-effect-but-not-in-texas\n",
      "Getting content from URL: https://www.wbrz.com/news/biden-administration-policy-expanding-title-ix-protections-to-lgbtq-students-take-effect/\n",
      "Getting content from URL: https://www.universityherald.com/articles/79156/20240801/biden-title-ix-overhaul-college-gender-identity-sex-discrimination-trump-transgender.htm\n",
      "Getting content from URL: https://www.foxnews.com/opinion/biden-harris-4-most-dangerous-title-ix-changes-girls\n",
      "Getting content from URL: https://www.politico.com/news/2024/07/30/biden-title-ix-policies-schools-00171797\n",
      "Error with request\n",
      "Getting content from URL: https://www.edweek.org/policy-politics/bidens-title-ix-rule-takes-effect-amid-a-confusing-legal-landscape/2024/07\n",
      "Getting content from URL: https://www.usatoday.com/story/news/nation/2024/08/01/biden-title-ix-rules-stalled-state-challenges/74530041007/\n",
      "Getting content from URL: https://www.insidehighered.com/news/government/2024/08/01/how-legal-challenges-tied-title-ix-26-states\n",
      "Getting content from URL: https://www.nytimes.com/2024/08/01/us/politics/biden-title-ix-gender-sex-discrimination.html\n",
      "Error with request\n",
      "Getting content from URL: https://scdailygazette.com/briefs/court-ruling-blocks-new-title-ix-rules-in-schools-colleges-across-sc/\n",
      "Getting content from URL: https://www.keranews.org/education/2024-08-01/title-ix-changes-expanding-lgbtq-protections-go-into-effect-but-not-in-texas\n",
      "Getting content from URL: https://www.wbrz.com/news/biden-administration-policy-expanding-title-ix-protections-to-lgbtq-students-take-effect/\n",
      "Getting content from URL: https://www.universityherald.com/articles/79156/20240801/biden-title-ix-overhaul-college-gender-identity-sex-discrimination-trump-transgender.htm\n",
      "Getting content from URL: https://www.foxnews.com/opinion/biden-harris-4-most-dangerous-title-ix-changes-girls\n",
      "Getting content from URL: https://www.politico.com/news/2024/07/30/biden-title-ix-policies-schools-00171797\n",
      "Error with request\n",
      "Getting content from URL: https://www.edweek.org/policy-politics/bidens-title-ix-rule-takes-effect-amid-a-confusing-legal-landscape/2024/07\n",
      "Getting content from URL: https://azmirror.com/2024/04/09/abortions-are-banned-in-arizona-after-the-supreme-court-upholds-an-1864-law/\n",
      "Getting content from URL: https://apnews.com/article/arizona-abortion-restrictions-1864-9c68866d69dca38c728dd27b80592e8f\n",
      "Getting content from URL: https://time.com/6965338/arizona-supreme-court-abortion-ban/\n",
      "Getting content from URL: https://www.nbcnews.com/politics/arizona-supreme-court-ruling-abortion-ban-rcna146915\n",
      "Getting content from URL: https://www.courthousenews.com/arizona-supreme-court-revives-near-total-ban-on-abortion/\n",
      "Error with request\n",
      "Getting content from URL: https://azcapitoltimes.com/news/2024/04/30/arizona-attorney-general-takes-another-pass-at-delaying-enforcement-of-abortion-ban/\n",
      "Getting content from URL: https://prismreports.org/2024/04/11/arizona-supreme-court-abortion-ban-ruling/\n",
      "Getting content from URL: https://msmagazine.com/2024/02/12/arizona-supreme-court-abortions-emergency-life/\n",
      "Getting content from URL: https://www.nytimes.com/2024/04/09/us/arizona-abortion-ban.html\n",
      "Error with request\n",
      "Getting content from URL: https://thehill.com/homenews/state-watch/4661666-arizona-supreme-court-grants-stay-preventing-1864-abortion-ban-from-taking-effect/\n",
      "Error with request\n",
      "Getting content from URL: https://azmirror.com/2024/04/09/abortions-are-banned-in-arizona-after-the-supreme-court-upholds-an-1864-law/\n",
      "Getting content from URL: https://apnews.com/article/arizona-abortion-restrictions-1864-9c68866d69dca38c728dd27b80592e8f\n",
      "Getting content from URL: https://time.com/6965338/arizona-supreme-court-abortion-ban/\n",
      "Getting content from URL: https://www.nbcnews.com/politics/arizona-supreme-court-ruling-abortion-ban-rcna146915\n",
      "Getting content from URL: https://www.courthousenews.com/arizona-supreme-court-revives-near-total-ban-on-abortion/\n",
      "Error with request\n",
      "Getting content from URL: https://azcapitoltimes.com/news/2024/04/30/arizona-attorney-general-takes-another-pass-at-delaying-enforcement-of-abortion-ban/\n",
      "Getting content from URL: https://prismreports.org/2024/04/11/arizona-supreme-court-abortion-ban-ruling/\n",
      "Getting content from URL: https://msmagazine.com/2024/02/12/arizona-supreme-court-abortions-emergency-life/\n",
      "Getting content from URL: https://www.nytimes.com/2024/04/09/us/arizona-abortion-ban.html\n",
      "Error with request\n",
      "Getting content from URL: https://thehill.com/homenews/state-watch/4661666-arizona-supreme-court-grants-stay-preventing-1864-abortion-ban-from-taking-effect/\n",
      "Error with request\n",
      "Getting content from URL: https://azmirror.com/2024/04/09/abortions-are-banned-in-arizona-after-the-supreme-court-upholds-an-1864-law/\n",
      "Getting content from URL: https://apnews.com/article/arizona-abortion-restrictions-1864-9c68866d69dca38c728dd27b80592e8f\n",
      "Getting content from URL: https://time.com/6965338/arizona-supreme-court-abortion-ban/\n",
      "Getting content from URL: https://www.nbcnews.com/politics/arizona-supreme-court-ruling-abortion-ban-rcna146915\n",
      "Getting content from URL: https://www.courthousenews.com/arizona-supreme-court-revives-near-total-ban-on-abortion/\n",
      "Error with request\n",
      "Getting content from URL: https://azcapitoltimes.com/news/2024/04/30/arizona-attorney-general-takes-another-pass-at-delaying-enforcement-of-abortion-ban/\n",
      "Getting content from URL: https://prismreports.org/2024/04/11/arizona-supreme-court-abortion-ban-ruling/\n",
      "Getting content from URL: https://msmagazine.com/2024/02/12/arizona-supreme-court-abortions-emergency-life/\n",
      "Getting content from URL: https://www.nytimes.com/2024/04/09/us/arizona-abortion-ban.html\n",
      "Error with request\n",
      "Getting content from URL: https://thehill.com/homenews/state-watch/4661666-arizona-supreme-court-grants-stay-preventing-1864-abortion-ban-from-taking-effect/\n",
      "Error with request\n",
      "Getting content from URL: https://azmirror.com/2024/04/09/abortions-are-banned-in-arizona-after-the-supreme-court-upholds-an-1864-law/\n",
      "Getting content from URL: https://apnews.com/article/arizona-abortion-restrictions-1864-9c68866d69dca38c728dd27b80592e8f\n",
      "Getting content from URL: https://time.com/6965338/arizona-supreme-court-abortion-ban/\n",
      "Getting content from URL: https://www.nbcnews.com/politics/arizona-supreme-court-ruling-abortion-ban-rcna146915\n",
      "Getting content from URL: https://www.courthousenews.com/arizona-supreme-court-revives-near-total-ban-on-abortion/\n",
      "Error with request\n",
      "Getting content from URL: https://azcapitoltimes.com/news/2024/04/30/arizona-attorney-general-takes-another-pass-at-delaying-enforcement-of-abortion-ban/\n",
      "Getting content from URL: https://prismreports.org/2024/04/11/arizona-supreme-court-abortion-ban-ruling/\n",
      "Getting content from URL: https://msmagazine.com/2024/02/12/arizona-supreme-court-abortions-emergency-life/\n",
      "Getting content from URL: https://www.nytimes.com/2024/04/09/us/arizona-abortion-ban.html\n",
      "Error with request\n",
      "Getting content from URL: https://thehill.com/homenews/state-watch/4661666-arizona-supreme-court-grants-stay-preventing-1864-abortion-ban-from-taking-effect/\n",
      "Error with request\n",
      "Getting content from URL: https://azmirror.com/2024/04/09/abortions-are-banned-in-arizona-after-the-supreme-court-upholds-an-1864-law/\n",
      "Getting content from URL: https://apnews.com/article/arizona-abortion-restrictions-1864-9c68866d69dca38c728dd27b80592e8f\n",
      "Getting content from URL: https://time.com/6965338/arizona-supreme-court-abortion-ban/\n",
      "Getting content from URL: https://www.nbcnews.com/politics/arizona-supreme-court-ruling-abortion-ban-rcna146915\n",
      "Getting content from URL: https://www.courthousenews.com/arizona-supreme-court-revives-near-total-ban-on-abortion/\n",
      "Error with request\n",
      "Getting content from URL: https://azcapitoltimes.com/news/2024/04/30/arizona-attorney-general-takes-another-pass-at-delaying-enforcement-of-abortion-ban/\n",
      "Getting content from URL: https://prismreports.org/2024/04/11/arizona-supreme-court-abortion-ban-ruling/\n",
      "Getting content from URL: https://msmagazine.com/2024/02/12/arizona-supreme-court-abortions-emergency-life/\n",
      "Getting content from URL: https://www.nytimes.com/2024/04/09/us/arizona-abortion-ban.html\n",
      "Error with request\n",
      "Getting content from URL: https://thehill.com/homenews/state-watch/4661666-arizona-supreme-court-grants-stay-preventing-1864-abortion-ban-from-taking-effect/\n",
      "Error with request\n"
     ]
    }
   ],
   "source": [
    "event2 = add_content_to_event(event2)\n",
    "event3 = add_content_to_event(event3)\n",
    "event4 = add_content_to_event(event4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine and drop empty content\n",
    "events = pd.concat([event1, event2, event3, event4])\n",
    "events.drop(events[events['content'] == ''].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the final data to a new CSV file\n",
    "events.to_csv('news_results_content.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
